import io
import re
from datetime import datetime

import google.generativeai as genai
import pandas as pd
import PyPDF2
import streamlit as st
from gtts import gTTS
from PIL import Image
import docx  # t·ª´ python-docx

# --- IMPORT FILE PROMPTS ---
try:
    from prompts import get_expert_prompt
except ImportError:
    st.error("‚ö†Ô∏è L·ªói: Kh√¥ng t√¨m th·∫•y file 'prompts.py'. H√£y t·∫°o file n√†y c√πng th∆∞ m·ª•c.")
    st.stop()

# =============================================================================
# 1. C·∫§U H√åNH & H√ÄM H·ªñ TR·ª¢
# =============================================================================

st.set_page_config(
    page_title="Rin.Ai - Si√™u Tr·ª£ L√Ω AI",
    page_icon="üíé",
    layout="wide",
)


def process_uploaded_file(uploaded_file):
    """ƒê·ªçc n·ªôi dung file upload (·∫£nh, PDF, Excel, CSV, DOCX, TXT...)."""
    if uploaded_file is None:
        return None

    try:
        file_type = uploaded_file.type or ""
        file_name = uploaded_file.name.lower()

        # ·∫¢nh
        if file_type.startswith("image"):
            return Image.open(uploaded_file)

        # PDF
        if file_type == "application/pdf" or file_name.endswith(".pdf"):
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() or ""
            return text

        # CSV / Excel
        if (
            "excel" in file_type
            or "spreadsheet" in file_type
            or file_name.endswith(".csv")
            or file_name.endswith(".xlsx")
        ):
            if file_name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            return df.to_string(index=False)

        # Word (DOCX)
        if file_name.endswith(".docx"):
            doc = docx.Document(uploaded_file)
            text = "\n".join(p.text for p in doc.paragraphs)
            return text

        # Text th∆∞·ªùng
        raw = uploaded_file.getvalue()
        try:
            return raw.decode("utf-8")
        except UnicodeDecodeError:
            return raw.decode("latin-1")

    except Exception as e:
        return f"L·ªói ƒë·ªçc file: {e}"


def clean_text_for_tts(text: str) -> str:
    """L√†m s·∫°ch text ƒë·ªÉ ƒë·ªçc TTS (lo·∫°i b·ªõt Markdown, prompt k·ªπ thu·∫≠t)."""
    if not text:
        return ""

    clean = re.sub(
        r"###PROMPT_[23]D###.*?###END_PROMPT###",
        "",
        text,
        flags=re.DOTALL,
    )
    clean = clean.replace("**", "")
    clean = re.sub(r"`+", "", clean)
    clean = re.sub(r"\n{2,}", "\n", clean)
    return clean.strip()


def play_text_to_speech(text_content: str, speed_slow: bool = False):
    """ƒê·ªçc text b·∫±ng gTTS, ph√°t tr·ª±c ti·∫øp tr√™n Streamlit."""
    try:
        text_to_read = clean_text_for_tts(text_content)
        if len(text_to_read) < 5:
            return

        tts = gTTS(text=text_to_read, lang="vi", slow=speed_slow)
        audio_bytes = io.BytesIO()
        tts.write_to_fp(audio_bytes)
        audio_bytes.seek(0)

        st.audio(audio_bytes, format="audio/mp3")
        status = "üê¢ ƒêang ƒë·ªçc ch·∫≠m..." if speed_slow else "üêá ƒêang ƒë·ªçc t·ªëc ƒë·ªô th∆∞·ªùng..."
        st.caption(f"üîä {status}")
    except Exception:
        # Kh√¥ng ch·∫∑n app n·∫øu TTS l·ªói
        pass


def generate_image_url(prompt: str) -> str:
    """T·∫°o URL ·∫£nh t·ª´ Pollinations d·ª±a tr√™n prompt ti·∫øng Anh."""
    clean_prompt = prompt.replace(" ", "%20")
    return f"https://image.pollinations.ai/prompt/{clean_prompt}?nologo=true&model=turbo"


@st.cache_resource(show_spinner=False)
def get_available_models(api_key: str):
    """L·∫•y danh s√°ch model kh·∫£ d·ª•ng, ∆∞u ti√™n Flash/Pro."""
    try:
        genai.configure(api_key=api_key)
        models = list(genai.list_models())

        names = [
            m.name
            for m in models
            if "generateContent" in getattr(m, "supported_generation_methods", [])
        ]

        # ∆Øu ti√™n: 1.5 / 2.0 Flash & Pro
        candidates = [
            n
            for n in names
            if "gemini" in n
            and ("1.5" in n or "2.0" in n or "2.5" in n or "pro" in n or "flash" in n)
        ]

        if not candidates:
            candidates = names or ["gemini-1.5-flash"]

        # S·∫Øp x·∫øp: Flash tr∆∞·ªõc, Pro sau, 2.5 > 2.0 > 1.5
        def sort_key(x: str):
            return (
                "flash" not in x.lower(),
                "pro" not in x.lower(),
                "2.5" not in x,
                "2.0" not in x,
                "1.5" not in x,
            )

        candidates.sort(key=sort_key)
        return candidates
    except Exception:
        return ["gemini-1.5-flash"]


def get_model(model_name: str):
    """T·∫°o GenerativeModel ƒë√£ c·∫•u h√¨nh s·∫µn API key (genai.configure g·ªçi tr∆∞·ªõc)."""
    return genai.GenerativeModel(model_name)


# =============================================================================
# 2. SIDEBAR (THANH B√äN TR√ÅI)
# =============================================================================

with st.sidebar:
    st.image(
        "https://cdn-icons-png.flaticon.com/512/12222/12222588.png",
        width=80,
    )
    st.title("RIN.AI PRO")
    st.caption("Developed by Mr. H·ªçc")
    st.divider()

    # --- NH·∫¨P KEY ---
    st.subheader("üîë T√†i kho·∫£n & C·∫•u h√¨nh")
    key_option = st.radio(
        "Ch·∫ø ƒë·ªô:",
        ["üöÄ D√πng Mi·ªÖn Ph√≠", "üíé Nh·∫≠p Key C·ªßa B·∫°n"],
        label_visibility="collapsed",
    )
    final_key = None

    if key_option == "üöÄ D√πng Mi·ªÖn Ph√≠":
        try:
            final_key = st.secrets["GOOGLE_API_KEY"]
            st.success("‚úÖ ƒê√£ k·∫øt n·ªëi Server chung")
        except Exception:
            st.error("‚ùå Ch∆∞a c·∫•u h√¨nh Key chung tr√™n server.")
    else:
        st.info("Nh·∫≠p Google API Key:")
        st.markdown(
            "[üëâ B·∫•m v√†o ƒë√¢y ƒë·ªÉ l·∫•y Key mi·ªÖn ph√≠](https://aistudio.google.com/app/apikey)"
        )
        final_key = st.text_input("D√°n Key v√†o ƒë√¢y:", type="password")
        if final_key:
            st.success("‚úÖ ƒê√£ nh·∫≠n Key c√° nh√¢n")

    # --- CH·ªåN MODEL ---
    global current_model_name  # d√πng bi·∫øn to√†n c·ª•c
    if final_key:
        available_models = get_available_models(final_key)
        selected_model_display = st.selectbox(
            "üß† Ch·ªçn b·ªô n√£o AI:",
            available_models,
            index=0,
        )
        current_model_name = selected_model_display
        st.caption(f"ƒêang d√πng model: `{current_model_name}`")

    st.divider()

    # --- MENU C√îNG C·ª§ THAM KH·∫¢O ---
    st.subheader("üî• C√¥ng C·ª• M·ªü R·ªông")
    st.link_button("ü§ñ M·ªü App ChatGPT", "https://chatgpt.com/")
    with st.expander("üåê Google AI Tools (Full)"):
        st.link_button("üíé Gemini Chat", "https://gemini.google.com/")
        st.link_button("üìö NotebookLM", "https://notebooklm.google.com/")
        st.link_button("üõ†Ô∏è AI Studio", "https://aistudio.google.com/")
        st.link_button(
            "üé® ImageFX",
            "https://aitestkitchen.withgoogle.com/tools/image-fx",
        )
        st.link_button(
            "üé• VideoFX",
            "https://aitestkitchen.withgoogle.com/tools/video-fx",
        )
        st.link_button(
            "üéµ MusicFX",
            "https://aitestkitchen.withgoogle.com/tools/music-fx",
        )

    with st.expander("üìù VƒÉn ph√≤ng (Workspace)"):
        st.link_button("Google Docs", "https://docs.google.com/")
        st.link_button("Google Sheets", "https://sheets.google.com/")

    st.divider()

    # --- UPLOAD FILE ---
    st.subheader("üìé ƒê√≠nh K√®m T√†i Li·ªáu")
    uploaded_file = st.file_uploader(
        "Ch·ªçn file:",
        type=["png", "jpg", "jpeg", "pdf", "txt", "csv", "xlsx", "docx"],
        label_visibility="collapsed",
    )
    file_content = None
    if uploaded_file:
        file_content = process_uploaded_file(uploaded_file)
        st.success(f"‚úÖ ƒê√£ nh·∫≠n: {uploaded_file.name}")

    st.divider()

    # --- MENU CH√çNH ---
    st.subheader("üìÇ Ch·ªçn Chuy√™n Gia")
    menu = st.selectbox(
        "Lƒ©nh v·ª±c h·ªó tr·ª£:",
        [
            "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu",
            "‚ú® Tr·ª£ L√Ω ƒêa Lƒ©nh V·ª±c (Chung)",
            "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch",
            "üé® Thi·∫øt K·∫ø & Media (·∫¢nh/Video/Voice)",
            "üñ•Ô∏è Chuy√™n Gia Tin H·ªçc VƒÉn Ph√≤ng (Office)",
            "üèóÔ∏è Ki·∫øn Tr√∫c - N·ªôi Th·∫•t - X√¢y D·ª±ng",
            "üèõÔ∏è Tr·ª£ L√Ω C√°n b·ªô ·ª¶y ban (X√£/Ph∆∞·ªùng/TP)",
            "üèõÔ∏è D·ªãch V·ª• H√†nh Ch√≠nh C√¥ng",
            "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o",
            "üé• Chuy√™n Gia Video Google Veo",
            "üëî Nh√¢n S·ª± - Tuy·ªÉn D·ª•ng - CV",
            "‚öñÔ∏è Lu·∫≠t - H·ª£p ƒê·ªìng - H√†nh Ch√≠nh",
            "üí∞ Kinh Doanh & Marketing",
            "üè¢ Gi√°m ƒê·ªëc & Qu·∫£n Tr·ªã (CEO)",
            "üõí TMƒêT (Shopee/TikTok Shop)",
            "üíª L·∫≠p Tr√¨nh - Freelancer - Digital",
            "‚ù§Ô∏è Y T·∫ø - S·ª©c Kh·ªèe - Gym",
            "‚úàÔ∏è Du L·ªãch - L·ªãch Tr√¨nh - Vi Vu",
            "üß† T√¢m L√Ω - C·∫£m X√∫c - Tinh Th·∫ßn",
            "üçΩÔ∏è Nh√† H√†ng - F&B - ·∫®m Th·ª±c",
            "üì¶ Logistic - V·∫≠n H√†nh - Kho B√£i",
            "üìä K·∫ø To√°n - B√°o C√°o - S·ªë Li·ªáu",
            "üé§ S·ª± Ki·ªán - MC - H·ªôi Ngh·ªã",
            "üè† B·∫•t ƒê·ªông S·∫£n & Xe Sang",
        ],
    )

# =============================================================================
# 3. LOGIC CH√çNH (MAIN APP)
# =============================================================================

# N·∫øu ch∆∞a c√≥ key v√† kh√¥ng ph·∫£i trang gi·ªõi thi·ªáu => y√™u c·∫ßu nh·∫≠p
if not final_key and menu != "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu":
    st.warning("üëã Vui l√≤ng nh·∫≠p Google API Key b√™n tay tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

# C·∫•u h√¨nh Gemini (1 l·∫ßn)
if final_key:
    genai.configure(api_key=final_key)

# --- TRANG CH·ª¶ ---
if menu == "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu":
    st.title("üíé H·ªá Sinh Th√°i AI Th·ª±c Chi·∫øn - Rin.Ai")
    st.markdown("---")
    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown(
            """
        ### üëã Ch√†o m·ª´ng ƒë·∫øn v·ªõi Rin.Ai PRO
        **S·∫£n ph·∫©m t√¢m huy·∫øt ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi: _Mr. H·ªçc_**

        Rin.Ai l√† "Super App" t√≠ch h·ª£p s·ª©c m·∫°nh Google AI ƒë·ªÉ:
        - H·ªó tr·ª£ c√¥ng vi·ªác vƒÉn ph√≤ng, kinh doanh, marketing
        - Gi√∫p h·ªçc t·∫≠p, nghi√™n c·ª©u, luy·ªán thi
        - T·ª± ƒë·ªông ho√° tr√™n n·ªÅn t·∫£ng Google (Docs, Sheets, Slides...)
        """
        )
        st.link_button(
            "üëâ Chat Zalo v·ªõi Mr. H·ªçc",
            "https://zalo.me/0901108788",
        )
    with col2:
        st.image(
            "https://cdn.dribbble.com/users/527451/screenshots/14972580/media/7f4288f6c3eb988a2879a953e5b12854.jpg"
        )

# --- MODULE: ƒê·ªåC TIN & T√ìM T·∫ÆT S√ÅCH ---
elif menu == "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch":
    st.header("üì∞ Chuy√™n Gia Tri Th·ª©c & Tin T·ª©c")
    today_str = datetime.now().strftime("%d/%m/%Y")

    task = st.radio(
        "Ch·∫ø ƒë·ªô:",
        ["üîé Tin T·ª©c Th·ªùi S·ª±", "üìö T√≥m t·∫Øt S√°ch/T√†i li·ªáu"],
        horizontal=True,
    )

    if task == "üîé Tin T·ª©c Th·ªùi S·ª±":
        topic = st.text_input(f"Nh·∫≠p ch·ªß ƒë·ªÅ tin t·ª©c ({today_str}):")
        if st.button("üîé Ph√¢n t√≠ch tin t·ª©c"):
            if topic:
                with st.spinner(f"ƒêang ph√¢n t√≠ch b·∫±ng model {current_model_name}..."):
                    try:
                        model = get_model(current_model_name)
                        prompt = (
                            f"H√£y t√≥m t·∫Øt c√°c tin t·ª©c m·ªõi nh·∫•t (n·∫øu c√≥ th·ªÉ) v·ªÅ ch·ªß ƒë·ªÅ: {topic} "
                            f"t√≠nh ƒë·∫øn ng√†y {today_str}. "
                            "Tr√¨nh b√†y ng·∫Øn g·ªçn, c√≥ bullet, v√† n·∫øu c√≥ th·ªÉ h√£y g·ª£i √Ω c√°c t·ª´ kho√° ƒë·ªÉ ng∆∞·ªùi d√πng t·ª± tra c·ª©u th√™m."
                        )
                        res = model.generate_content(prompt)
                        text = res.text
                        st.success("‚úÖ K·∫øt qu·∫£ t·ªïng h·ª£p:")
                        st.markdown(text)
                        play_text_to_speech(text)
                    except Exception as e:
                        st.error(f"L·ªói Model {current_model_name}: {e}")
                        st.info(
                            "üí° M·∫πo: H√£y th·ª≠ ƒë·ªïi sang model 'gemini-1.5-flash' ·ªü thanh b√™n tr√°i."
                        )
    else:
        st.subheader("üìö T√≥m t·∫Øt t√†i li·ªáu / s√°ch")
        txt_input = st.text_area("D√°n n·ªôi dung, ho·∫∑c ch·ªâ c·∫ßn upload file ·ªü thanh b√™n tr√°i:")
        content = file_content if file_content is not None else txt_input

        if st.button("üìö T√≥m t·∫Øt") and content:
            with st.spinner(f"ƒêang t√≥m t·∫Øt b·∫±ng model {current_model_name}..."):
                try:
                    model = get_model(current_model_name)
                    if isinstance(content, Image.Image):
                        req = [
                            "T√≥m t·∫Øt n·ªôi dung ch√≠nh trong h√¨nh sau (n·∫øu l√† trang s√°ch/t√†i li·ªáu):",
                            content,
                        ]
                    else:
                        req = [
                            f"H√£y t√≥m t·∫Øt n·ªôi dung sau th√†nh 5‚Äì7 √Ω ch√≠nh, d·ªÖ hi·ªÉu cho ng∆∞·ªùi Vi·ªát:\n\n{content}"
                        ]
                    res = model.generate_content(req)
                    text = res.text
                    st.markdown(text)
                    play_text_to_speech(text)
                except Exception as e:
                    st.error(f"L·ªói: {e}")

# --- MODULE: MEDIA (·∫¢NH / VIDEO PROMPT / VOICE) ---
elif menu == "üé® Thi·∫øt K·∫ø & Media (·∫¢nh/Video/Voice)":
    st.header("üé® Studio ƒêa Ph∆∞∆°ng Ti·ªán ‚Äì Rin.Ai")
    mode = st.radio(
        "C√¥ng c·ª•:",
        ["üñºÔ∏è T·∫°o ·∫¢nh", "üé¨ T·∫°o Prompt Video", "üéôÔ∏è Voice AI"],
        horizontal=True,
    )

    # ·∫¢NH
    if mode == "üñºÔ∏è T·∫°o ·∫¢nh":
        desc = st.text_area("Nh·∫≠p m√¥ t·∫£ H√åNH ·∫¢NH (ti·∫øng Vi·ªát):")
        if st.button("üé® V·∫Ω Ngay") and desc:
            with st.spinner("ƒêang chuy·ªÉn prompt sang ti·∫øng Anh & t·∫°o ·∫£nh..."):
                try:
                    model = get_model(current_model_name)
                    p_en = model.generate_content(
                        f"Translate this image prompt to natural English, concise but detailed: {desc}"
                    ).text
                    img_url = generate_image_url(p_en)
                    st.image(img_url, caption="·∫¢nh AI t·∫°o b·ªüi Rin.Ai (Pollinations)")
                except Exception as e:
                    st.error(f"L·ªói t·∫°o ·∫£nh: {e}")

    # VIDEO PROMPT
    elif mode == "üé¨ T·∫°o Prompt Video":
        idea = st.text_area("√ù t∆∞·ªüng video (ti·∫øng Vi·ªát):")
        if st.button("üé• Vi·∫øt Prompt") and idea:
            with st.spinner("ƒêang vi·∫øt Video Prompt ti·∫øng Anh..."):
                try:
                    model = get_model(current_model_name)
                    prompt_en = model.generate_content(
                        f"Create a professional English video prompt for Veo/Sora/Runway based on this idea (in Vietnamese): {idea}"
                        "\n\nOutput only the final English prompt, no explanation."
                    ).text
                    st.code(prompt_en, language="markdown")
                except Exception as e:
                    st.error(f"L·ªói: {e}")

    # VOICE
    elif mode == "üéôÔ∏è Voice AI":
        c1, c2 = st.columns(2)
        is_slow = c1.checkbox("üê¢ ƒê·ªçc ch·∫≠m", value=False)
        tone = c2.selectbox("Gi·ªçng ƒë·ªçc:", ["Truy·ªÅn c·∫£m", "Vui v·∫ª", "Nghi√™m t√∫c"])
        txt = st.text_area("Nh·∫≠p n·ªôi dung mu·ªën ƒë·ªçc:")

        if st.button("üéôÔ∏è ƒê·ªçc") and txt:
            st.info(f"Gi·ªçng: {tone}")
            play_text_to_speech(txt, is_slow)

# --- MODULE: C√ÅC CHUY√äN GIA THEO NG√ÄNH ---
else:
    st.header(menu)
    expert_instruction = get_expert_prompt(menu)

    # B·ªï sung c·∫•u h√¨nh ri√™ng cho Gi√°o d·ª•c
    system_append = ""
    if menu == "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o":
        c1, c2 = st.columns(2)
        sach = c1.selectbox(
            "B·ªô s√°ch:",
            ["C√°nh Di·ªÅu", "K·∫øt N·ªëi Tri Th·ª©c", "Ch√¢n Tr·ªùi S√°ng T·∫°o"],
        )
        role = c2.radio("Vai tr√≤:", ["H·ªçc sinh", "Gi√°o vi√™n", "Ph·ª• huynh"], horizontal=True)
        system_append = f"\n(B·ªô s√°ch: {sach}, ƒê·ªëi t∆∞·ª£ng: {role})."

    # Kh·ªüi t·∫°o l·ªãch s·ª≠ chat
    if "history" not in st.session_state:
        st.session_state.history = {}

    if menu not in st.session_state.history:
        st.session_state.history[menu] = [
            {
                "role": "assistant",
                "content": f"Xin ch√†o! T√¥i l√† chuy√™n gia trong lƒ©nh v·ª±c **{menu}**. B·∫°n c·∫ßn h·ªó tr·ª£ ƒëi·ªÅu g√¨?",
            }
        ]

    # Hi·ªÉn th·ªã l·ªãch s·ª≠
    for msg in st.session_state.history[menu]:
        if msg["role"] == "user":
            with st.chat_message("user"):
                st.markdown(msg["content"])
        else:
            clean_show = re.sub(
                r"###PROMPT_[23]D###.*?###END_PROMPT###",
                "",
                msg["content"],
                flags=re.DOTALL,
            )
            if clean_show.strip():
                with st.chat_message("assistant"):
                    st.markdown(clean_show)

    # √î nh·∫≠p chat
    user_prompt = st.chat_input("G·ª≠i y√™u c·∫ßu...")

    if user_prompt:
        # Hi·ªÉn th·ªã user chat
        with st.chat_message("user"):
            st.markdown(user_prompt)
            if file_content is not None and uploaded_file is not None:
                st.caption(f"üìé ƒê√≠nh k√®m: {uploaded_file.name}")

        st.session_state.history[menu].append(
            {"role": "user", "content": user_prompt}
        )

        # G·ªçi Gemini
        with st.chat_message("assistant"):
            with st.spinner(f"Chuy√™n gia ({current_model_name}) ƒëang ph√¢n t√≠ch..."):
                try:
                    final_prompt = user_prompt + system_append
                    message_payload = []

                    if file_content is not None:
                        # N·∫øu l√† ·∫£nh -> g·ª≠i multimodal
                        if isinstance(file_content, Image.Image):
                            message_payload = [final_prompt, file_content]
                        else:
                            final_prompt += (
                                "\n\n=== FILE DATA ===\n"
                                f"{file_content}\n"
                                "================="
                            )
                            message_payload = [final_prompt]
                    else:
                        message_payload = [final_prompt]

                    model = get_model(current_model_name)
                    chat = model.start_chat(
                        system_instruction=expert_instruction,
                        history=[],
                    )
                    response = chat.send_message(message_payload)
                    full_txt = response.text

                    # L·∫•y prompt 2D/3D n·∫øu c√≥
                    p2d = re.search(
                        r"###PROMPT_2D###(.*?)###END_PROMPT###",
                        full_txt,
                        re.DOTALL,
                    )
                    p3d = re.search(
                        r"###PROMPT_3D###(.*?)###END_PROMPT###",
                        full_txt,
                        re.DOTALL,
                    )
                    txt_show = re.sub(
                        r"###PROMPT_[23]D###.*?###END_PROMPT###",
                        "",
                        full_txt,
                        flags=re.DOTALL,
                    )

                    st.markdown(txt_show.strip())

                    # N·∫øu c√≥ prompt v·∫Ω, hi·ªÉn th·ªã th√™m ·∫£nh
                    if p2d or p3d:
                        st.divider()
                        col_a, col_b = st.columns(2)
                        if p2d:
                            with col_a:
                                st.image(
                                    generate_image_url(
                                        "Blueprint floor plan. " + p2d.group(1)
                                    ),
                                    caption="B·∫£n v·∫Ω 2D (demo AI)",
                                )
                        if p3d:
                            with col_b:
                                st.image(
                                    generate_image_url(
                                        "Architecture render 8k. " + p3d.group(1)
                                    ),
                                    caption="Ph·ªëi c·∫£nh 3D (demo AI)",
                                )

                    st.session_state.history[menu].append(
                        {"role": "assistant", "content": full_txt}
                    )

                    # Gi·ªõi h·∫°n l·ªãch s·ª≠ cho nh·∫π RAM
                    if len(st.session_state.history[menu]) > 40:
                        st.session_state.history[menu] = st.session_state.history[
                            menu
                        ][:40]

                except Exception as e:
                    st.error(f"L·ªói: {e}")
                    st.warning(
                        "‚ö†Ô∏è N·∫øu g·∫∑p l·ªói, h√£y th·ª≠ ƒë·ªïi sang model 'gemini-1.5-flash' ·ªü thanh b√™n tr√°i."
                    )
