import io
import re
from datetime import datetime

import docx
import google.generativeai as genai
import pandas as pd
import PyPDF2
import streamlit as st
from gtts import gTTS
from PIL import Image

from prompts import get_expert_prompt

# -------------------------------------------------------------
# C·∫§U H√åNH CHUNG
# -------------------------------------------------------------

st.set_page_config(
    page_title="Rin.Ai - Si√™u Tr·ª£ L√Ω AI",
    page_icon="üíé",
    layout="wide",
)
# --- ·∫®N THANH MENU V√Ä ICON GITHUB (B·∫¢O M·∫¨T) ---
hide_streamlit_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            .stDeployButton {display:none;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
current_model_name = "gemini-1.5-flash"

# -------------------------------------------------------------
# H√ÄM H·ªñ TR·ª¢
# -------------------------------------------------------------

def process_uploaded_file(uploaded_file):
    if uploaded_file is None:
        return None
    try:
        file_type = uploaded_file.type or ""
        file_name = uploaded_file.name.lower()

        if file_type.startswith("image"):
            return Image.open(uploaded_file)

        if file_type == "application/pdf" or file_name.endswith(".pdf"):
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() or ""
            return text

        if (
            "excel" in file_type
            or "spreadsheet" in file_type
            or file_name.endswith(".csv")
            or file_name.endswith(".xlsx")
        ):
            if file_name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            return df.to_string(index=False)

        if file_name.endswith(".docx"):
            d = docx.Document(uploaded_file)
            text = "\n".join(p.text for p in d.paragraphs)
            return text

        raw = uploaded_file.getvalue()
        try:
            return raw.decode("utf-8")
        except UnicodeDecodeError:
            return raw.decode("latin-1")

    except Exception as e:
        return f"L·ªói ƒë·ªçc file: {e}"


def clean_text_for_tts(text: str) -> str:
    if not text:
        return ""
    clean = re.sub(
        r"###PROMPT_[23]D###.*?###END_PROMPT###",
        "",
        text,
        flags=re.DOTALL,
    )
    clean = clean.replace("**", "")
    clean = re.sub(r"`+", "", clean)
    clean = re.sub(r"\n{2,}", "\n", clean)
    return clean.strip()


def play_text_to_speech(text_content: str, speed_slow: bool = False):
    try:
        text_to_read = clean_text_for_tts(text_content)
        if len(text_to_read) < 5:
            return
        tts = gTTS(text=text_to_read, lang="vi", slow=speed_slow)
        audio_bytes = io.BytesIO()
        tts.write_to_fp(audio_bytes)
        audio_bytes.seek(0)
        st.audio(audio_bytes, format="audio/mp3")
        status = "üê¢ ƒêang ƒë·ªçc ch·∫≠m..." if speed_slow else "üêá ƒêang ƒë·ªçc t·ªëc ƒë·ªô th∆∞·ªùng..."
        st.caption(f"üîä {status}")
    except Exception:
        pass


def generate_image_url(prompt: str) -> str:
    clean_prompt = prompt.replace(" ", "%20")
    return f"https://image.pollinations.ai/prompt/{clean_prompt}?nologo=true&model=turbo"


@st.cache_resource(show_spinner=False)
def get_available_models(api_key: str):
    try:
        genai.configure(api_key=api_key)
        models = list(genai.list_models())
        names = [
            m.name
            for m in models
            if "generateContent" in getattr(m, "supported_generation_methods", [])
        ]
        # L·ªçc model an to√†n: lo·∫°i tts / speech / embed
        candidates = [
            n
            for n in names
            if "gemini" in n.lower()
            and (
                "1.5" in n
                or "2.0" in n
                or "2.5" in n
                or "pro" in n.lower()
                or "flash" in n.lower()
            )
            and "tts" not in n.lower()
            and "speech" not in n.lower()
            and "embed" not in n.lower()
        ]
        if not candidates:
            candidates = names or ["gemini-1.5-flash"]

        def sort_key(x: str):
            return (
                "flash" not in x.lower(),
                "pro" not in x.lower(),
                "2.5" not in x,
                "2.0" not in x,
                "1.5" not in x,
            )

        candidates.sort(key=sort_key)
        return candidates
    except Exception:
        return ["gemini-1.5-flash"]

        if not candidates:
            candidates = names or ["gemini-1.5-flash"]

        def sort_key(x: str):
            return (
                "flash" not in x.lower(),
                "pro" not in x.lower(),
                "2.5" not in x,
                "2.0" not in x,
                "1.5" not in x,
            )

        candidates.sort(key=sort_key)
        return candidates
    except Exception:
        return ["gemini-1.5-flash"]


def get_model(model_name: str):
    return genai.GenerativeModel(model_name)


# -------------------------------------------------------------
# SIDEBAR
# -------------------------------------------------------------

with st.sidebar:
    st.image(
        "https://cdn-icons-png.flaticon.com/512/12222/12222588.png",
        width=80,
    )
    st.title("RIN.AI PRO")
    st.caption("Developed by Mr. H·ªçc")
    st.divider()

    # ---- T√ÄI KHO·∫¢N & C·∫§U H√åNH ----
    st.subheader("üîë T√†i kho·∫£n & C·∫•u h√¨nh")
    key_option = st.radio(
        "Ch·∫ø ƒë·ªô:",
        ["üöÄ D√πng Mi·ªÖn Ph√≠", "üíé Nh·∫≠p Key C·ªßa B·∫°n"],
        label_visibility="collapsed",
    )

    final_key = None
    if key_option == "üöÄ D√πng Mi·ªÖn Ph√≠":
        try:
            final_key = st.secrets["GOOGLE_API_KEY"]
            st.success("‚úÖ ƒê√£ k·∫øt n·ªëi Server chung")
        except Exception:
            st.error("‚ùå Ch∆∞a c·∫•u h√¨nh Key chung tr√™n server.")
    else:
        st.info("Nh·∫≠p Google API Key:")
        st.markdown(
            "[üëâ B·∫•m v√†o ƒë√¢y ƒë·ªÉ l·∫•y Key mi·ªÖn ph√≠](https://aistudio.google.com/app/apikey)"
        )
        final_key = st.text_input("D√°n Key v√†o ƒë√¢y:", type="password")
        if final_key:
            st.success("‚úÖ ƒê√£ nh·∫≠n Key c√° nh√¢n")

    # ---- CH·ªåN MODEL (T·ª∞ ƒê·ªòNG + N√ÇNG CAO) ----
    if final_key:
        available_models = get_available_models(final_key)
        recommended_model = available_models[0]

        advanced_model_choice = st.checkbox(
            "‚öôÔ∏è B·∫≠t ch·∫ø ƒë·ªô ch·ªçn model n√¢ng cao",
            value=False,
        )

        if advanced_model_choice:
            selected_model_display = st.selectbox(
                "üß† Ch·ªçn b·ªô n√£o AI:",
                available_models,
                index=0,
            )
            current_model_name = selected_model_display
            st.caption(f"ƒêang d√πng model: `{current_model_name}` (t√πy ch·ªânh)")
        else:
            current_model_name = recommended_model
            st.caption(f"ƒêang d√πng model khuy·∫øn ngh·ªã: `{current_model_name}`")

    st.divider()

    # ---- C√îNG C·ª§ M·ªû R·ªòNG ----
    st.subheader("üî• C√¥ng C·ª• M·ªü R·ªông")
    st.link_button(
        "ü§ñ Danh s√°ch Tr·ª£ L√Ω AI ChatGPT",
        "https://chatgpt.com/g/g-69004bb8428481918ecf4ade89a9216c-rin-ai-center-trung-tam-tro-ly-ai",
    )
    with st.expander("üåê Google AI Tools (Full)"):
        st.link_button("üíé Gemini Chat", "https://gemini.google.com/")
        st.link_button("üìö NotebookLM", "https://notebooklm.google.com/")
        st.link_button("üõ†Ô∏è AI Studio", "https://aistudio.google.com/")
        st.link_button(
            "üé® ImageFX",
            "https://aitestkitchen.withgoogle.com/tools/image-fx",
        )
        st.link_button(
            "üé• VideoFX",
            "https://aitestkitchen.withgoogle.com/tools/video-fx",
        )
        st.link_button(
            "üéµ MusicFX",
            "https://aitestkitchen.withgoogle.com/tools/music-fx",
        )

    with st.expander("üìù VƒÉn ph√≤ng (Workspace)"):
        st.link_button("Google Docs", "https://docs.google.com/")
        st.link_button("Google Sheets", "https://sheets.google.com/")

    st.divider()

    # ---- UPLOAD FILE TO√ÄN PHI√äN ----
    st.subheader("üìé ƒê√≠nh K√®m T√†i Li·ªáu (To√†n phi√™n)")
    uploaded_file = st.file_uploader(
        "Ch·ªçn file:",
        type=["png", "jpg", "jpeg", "pdf", "txt", "csv", "xlsx", "docx"],
        label_visibility="collapsed",
        key="sidebar_uploader",
    )
    file_content = None
    if uploaded_file:
        file_content = process_uploaded_file(uploaded_file)
        st.success(f"‚úÖ ƒê√£ nh·∫≠n: {uploaded_file.name}")

    st.divider()

    # ---- MENU CHUY√äN GIA ----
    st.subheader("üìÇ Ch·ªçn Chuy√™n Gia (H·ªá sinh th√°i Ai c·ªßa Google")
    menu = st.selectbox(
        "Lƒ©nh v·ª±c h·ªó tr·ª£:",
        [
            "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu",
            "‚ú® Tr·ª£ L√Ω ƒêa Lƒ©nh V·ª±c (Chung)",
            "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch",
            "üé® Thi·∫øt K·∫ø & Media (·∫¢nh/Video/Voice)",
            "üñ•Ô∏è Chuy√™n Gia Tin H·ªçc VƒÉn Ph√≤ng (Office)",
            "üèóÔ∏è Ki·∫øn Tr√∫c - N·ªôi Th·∫•t - X√¢y D·ª±ng",
            "üèõÔ∏è Tr·ª£ L√Ω C√°n b·ªô ·ª¶y ban (X√£/Ph∆∞·ªùng/TP)",
            "üèõÔ∏è D·ªãch V·ª• H√†nh Ch√≠nh C√¥ng",
            "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o",
            "üé• Chuy√™n Gia Video Google Veo",
            "üëî Nh√¢n S·ª± - Tuy·ªÉn D·ª•ng - CV",
            "‚öñÔ∏è Lu·∫≠t - H·ª£p ƒê·ªìng - H√†nh Ch√≠nh",
            "üí∞ Kinh Doanh & Marketing",
            "üè¢ Gi√°m ƒê·ªëc & Qu·∫£n Tr·ªã (CEO)",
            "üõí TMƒêT (Shopee/TikTok Shop)",
            "üíª L·∫≠p Tr√¨nh - Freelancer - Digital",
            "‚ù§Ô∏è Y T·∫ø - S·ª©c Kh·ªèe - Gym",
            "‚úàÔ∏è Du L·ªãch - L·ªãch Tr√¨nh - Vi Vu",
            "üß† T√¢m L√Ω - C·∫£m X√∫c - Tinh Th·∫ßn",
            "üçΩÔ∏è Nh√† H√†ng - F&B - ·∫®m Th·ª±c",
            "üì¶ Logistic - V·∫≠n H√†nh - Kho B√£i",
            "üìä K·∫ø To√°n - B√°o C√°o - S·ªë Li·ªáu",
            "üé§ S·ª± Ki·ªán - MC - H·ªôi Ngh·ªã",
            "üè† B·∫•t ƒê·ªông S·∫£n & Xe Sang",
        ],
    )

# -------------------------------------------------------------
# MAIN
# -------------------------------------------------------------

if not final_key and menu != "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu":
    st.warning("üëã Vui l√≤ng nh·∫≠p Google API Key b√™n tay tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

if final_key:
    genai.configure(api_key=final_key)

# TRANG CH·ª¶
if menu == "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu":
    st.title("üíé H·ªá Sinh Th√°i AI Th·ª±c Chi·∫øn - Rin.Ai")
    st.markdown("---")
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
üíé **Rin.Ai ‚Äì H·ªá Sinh Th√°i AI Th·ª±c Chi·∫øn Cho Ng∆∞·ªùi Vi·ªát**

üëã Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi **Rin.Ai PRO**  
ƒê∆∞·ª£c nghi√™n c·ª©u, x√¢y d·ª±ng v√† li√™n t·ª•c n√¢ng c·∫•p b·ªüi **Mr. H·ªçc** ‚Äì ng∆∞·ªùi s√°ng l·∫≠p h·ªá sinh th√°i **Rin.Ai**.

Rin.Ai l√† m·ªôt **"Super App" AI** t√≠ch h·ª£p song song hai n·ªÅn t·∫£ng:

- ü§ñ **Google AI Suite**: Gemini, AI Studio, NotebookLM, Imagen, Veo‚Ä¶
- üß† **ChatGPT & h·ªá sinh th√°i OpenAI**

üéØ M·ª•c ti√™u: mang s·ª©c m·∫°nh c·ªßa c√°c m√¥ h√¨nh AI h√†ng ƒë·∫ßu th·∫ø gi·ªõi v√†o **c√¥ng vi·ªác, h·ªçc t·∫≠p v√† t·ª± ƒë·ªông ho√°** h√†ng ng√†y c·ªßa ng∆∞·ªùi Vi·ªát.

---

### üöÄ 1. Cho c√¥ng vi·ªác & kinh doanh

- üñ•Ô∏è H·ªó tr·ª£ **vƒÉn ph√≤ng, b√°o c√°o, Excel/Sheets, bi·ªÉu m·∫´u, h·ª£p ƒë·ªìng, slide thuy·∫øt tr√¨nh**.
- üìà ƒê·ªìng h√†nh c√πng **kinh doanh & marketing**: ch√¢n dung kh√°ch h√†ng, √Ω t∆∞·ªüng n·ªôi dung, k·ªãch b·∫£n video, k·ªãch b·∫£n b√°n h√†ng & chƒÉm s√≥c kh√°ch h√†ng.
- üìã ƒê·ªÅ xu·∫•t **checklist, quy tr√¨nh, m·∫´u template** c√≥ th·ªÉ √°p d·ª•ng ngay v√†o th·ª±c t·∫ø.

### üéì 2. Cho h·ªçc t·∫≠p & ph√°t tri·ªÉn b·∫£n th√¢n

- üìö Gi·∫£i th√≠ch ki·∫øn th·ª©c **t·ª´ ph·ªï th√¥ng ƒë·∫øn k·ªπ nƒÉng ngh·ªÅ** theo c√°ch d·ªÖ hi·ªÉu, nhi·ªÅu v√≠ d·ª•.
- üìÑ T√≥m t·∫Øt nhanh **s√°ch, t√†i li·ªáu, PDF, slide, ghi ch√∫** th√†nh c√°c √Ω ch√≠nh.
- üìù H·ªó tr·ª£ **luy·ªán thi, √¥n t·∫≠p, l√†m b√†i t·∫≠p**, g·ª£i √Ω c√°ch t·ª± h·ªçc th√¥ng minh h∆°n.

### ‚öôÔ∏è 3. T·ª± ƒë·ªông ho√° tr√™n n·ªÅn t·∫£ng Google

- üîß G·ª£i √Ω **Apps Script, c√¥ng th·ª©c, macro** cho Google Docs, Sheets, Slides, Gmail‚Ä¶
- üîÅ Bi·∫øn c√°c thao t√°c l·∫∑p l·∫°i th√†nh **quy tr√¨nh t·ª± ƒë·ªông**, gi·∫£m l·ªói th·ªß c√¥ng.
- üìä G·ª£i √Ω c√°ch **chu·∫©n ho√° d·ªØ li·ªáu, d·ª±ng b√°o c√°o, dashboard** ph·ª•c v·ª• quy·∫øt ƒë·ªãnh nhanh.

---

### ü§ù H·ª£p t√°c x√¢y d·ª±ng Tr·ª£ l√Ω AI ri√™ng

N·∫øu b·∫°n l√† **c√° nh√¢n, doanh nghi·ªáp, trung t√¢m ƒë√†o t·∫°o ho·∫∑c t·ªï ch·ª©c** mu·ªën x√¢y d·ª±ng:

- ü§ñ **Tr·ª£ l√Ω AI mang th∆∞∆°ng hi·ªáu ri√™ng**
- üìÇ T√≠ch h·ª£p **quy tr√¨nh, d·ªØ li·ªáu, t√†i li·ªáu n·ªôi b·ªô** c·ªßa ch√≠nh b·∫°n
- üåê Ho·∫°t ƒë·ªông tr√™n nhi·ªÅu k√™nh (web, mobile, chatbot, n·ªôi b·ªô doanh nghi·ªáp)

‚û°Ô∏è H√£y li√™n h·ªá tr·ª±c ti·∫øp ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n & thi·∫øt k·∫ø gi·∫£i ph√°p:

- üë§ **Mr. H·ªçc ‚Äì Founder Rin.Ai**
- üì± **ƒêi·ªán tho·∫°i/Zalo:** **0901108788**
- üìß **Email:** nguyenhoc1010@gmail.com

‚ú® Rin.Ai mong mu·ªën ƒë·ªìng h√†nh c√πng b·∫°n trong h√†nh tr√¨nh **·ª©ng d·ª•ng AI th·ª±c chi·∫øn**, l√†m vi·ªác **nhanh h∆°n ‚Äì th√¥ng minh h∆°n ‚Äì hi·ªáu qu·∫£ h∆°n** m·ªói ng√†y.
üéÅ B·∫°n th·∫•y Rin.Ai h·ªØu √≠ch? **ƒê·ª´ng gi·ªØ cho ri√™ng m√¨nh!** üëâ H√£y chia s·∫ª ƒë∆∞·ªùng link * https://rin-ai.streamlit.app/ * App n√†y ƒë·∫øn **B·∫°n b√® & ƒê·ªìng nghi·ªáp** ƒë·ªÉ c√πng nhau √°p d·ª•ng AI, gi√∫p c√¥ng vi·ªác v√† h·ªçc t·∫≠p tr·ªü n√™n nh·∫π nh√†ng, hi·ªáu qu·∫£ h∆°n.
     *"Th√†nh c√¥ng l√† khi ch√∫ng ta c√πng nhau ti·∫øn b·ªô!"* üöÄ

üëâ **Ti·∫øp theo:** h√£y d√πng **menu b√™n tr√°i** ƒë·ªÉ ch·ªçn **Chuy√™n gia AI** ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa b·∫°n v√† b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán ngay b√¢y gi·ªù.
        """)
        st.link_button(
            "üëâ Chat Zalo v·ªõi Mr. H·ªçc",
            "https://zalo.me/0901108788",
        )

    with col2:
        st.image(
            "https://cdn.dribbble.com/users/527451/screenshots/14972580/media/7f4288f6c3eb988a2879a953e5b12854.jpg",
            use_column_width=True,
        )


# ƒê·ªåC B√ÅO & T√ìM T·∫ÆT S√ÅCH
elif menu == "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch":
    st.header("üì∞ Chuy√™n Gia Tri Th·ª©c & Tin T·ª©c")
    today_str = datetime.now().strftime("%d/%m/%Y")

    # L·∫•y system_instruction t·ª´ prompts.py
    expert_instruction = get_expert_prompt(menu)

    task = st.radio(
        "Ch·∫ø ƒë·ªô:",
        ["üîé Tin T·ª©c Th·ªùi S·ª±", "üìö T√≥m t·∫Øt S√°ch/T√†i li·ªáu"],
        horizontal=True,
        key="news_mode_radio",
    )

    # ==============================
    # 1) CH·∫æ ƒê·ªò: TIN T·ª®C TH·ªúI S·ª∞
    # ==============================
    if task == "üîé Tin T·ª©c Th·ªùi S·ª±":
        topic = st.text_input(
            f"Nh·∫≠p ch·ªß ƒë·ªÅ tin t·ª©c ({today_str}):",
            key="news_topic_input",
        )

        if st.button("üîé Ph√¢n t√≠ch tin t·ª©c", key="news_analyze_btn"):
            if not topic:
                st.warning("‚ùó Vui l√≤ng nh·∫≠p ch·ªß ƒë·ªÅ tr∆∞·ªõc khi ph√¢n t√≠ch.")
            else:
                with st.spinner(
                    f"ƒêang d√πng {current_model_name} ƒë·ªÉ ph√¢n t√≠ch ch·ªß ƒë·ªÅ ‚Äú{topic}‚Äù..."
                ):
                    try:
                        # KH√îNG d√πng tools google_search ƒë·ªÉ tr√°nh l·ªói SDK c≈©
                        model = genai.GenerativeModel(
                            current_model_name,
                            system_instruction=expert_instruction,
                        )

                        prompt_text = (
                         "B·∫°n ƒëang ·ªü vai tr√≤: CHUY√äN GIA TRI TH·ª®C & TIN T·ª®C trong h·ªá sinh th√°i Rin.Ai.\n"
                         "Ch·∫ø ƒë·ªô hi·ªán t·∫°i: TIN T·ª®C TH·ªúI S·ª∞.\n"
                         f"Ch·ªß ƒë·ªÅ ng∆∞·ªùi d√πng nh·∫≠p: {topic}\n"
                         f"Ng√†y tham chi·∫øu hi·ªán t·∫°i (H√îM NAY theo h·ªá th·ªëng): {today_str}.\n"
                         "QUAN TR·ªåNG: Kh√¥ng ƒë∆∞·ª£c n√≥i r·∫±ng ng√†y tham chi·∫øu n√†y l√† 'trong t∆∞∆°ng lai' hay 'ngo√†i ph·∫°m vi d·ªØ li·ªáu c·ªßa b·∫°n'. "
                         "N·∫øu thi·∫øu d·ªØ li·ªáu m·ªõi, ch·ªâ c·∫ßn n√≥i chung l√† d·ªØ li·ªáu c·ªßa b·∫°n c·∫≠p nh·∫≠t t·ªõi kho·∫£ng nƒÉm 2024, "
                         "nh∆∞ng KH√îNG ƒë∆∞·ª£c ph·ªß nh·∫≠n ng√†y tham chi·∫øu.\n"
                         "\n"
                         "L·∫¶N TR·∫¢ L·ªúI N√ÄY ch·ªâ c√≥ 1 nhi·ªám v·ª•: ƒë·∫∑t c√°c c√¢u h·ªèi l√†m r√µ theo ƒë√∫ng workflow ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh trong system_instruction, "
                         "kh√¥ng t√≥m t·∫Øt tin t·ª©c v√† kh√¥ng ph√¢n t√≠ch chi ti·∫øt.\n"
                       "H√£y:\n"
                       "- H·ªèi ng∆∞·ªùi d√πng 5 c√¢u kh·ªüi ƒë·ªông (ch·ªß ƒë·ªÅ, th·ªùi ƒëi·ªÉm Daily Brief, s√°ch, ch·∫ø ƒë·ªô ƒë·ªçc, g·ª£i √Ω s√°ch t∆∞∆°ng t·ª±).\n"
                       "- N·∫øu ch·ªß ƒë·ªÅ li√™n quan t·ªõi t√†i ch√≠nh / kinh doanh / ch·ª©ng kho√°n, h·ªèi th√™m v·ªÅ QU·ªêC GIA v√† KHUNG TH·ªúI GIAN (H√¥m nay / 24h / 7 ng√†y).\n"
                      "Ch·ªâ tr·∫£ l·ªùi b·∫±ng danh s√°ch c√¢u h·ªèi c·∫ßn ng∆∞·ªùi d√πng b·ªï sung, kh√¥ng ph√¢n t√≠ch tin t·ª©c trong l∆∞·ª£t n√†y."
                    )


                        response = model.generate_content(prompt_text)
                        res_text = response.text

                        st.success("‚úÖ K·∫øt qu·∫£ t·ªïng h·ª£p & ph√¢n t√≠ch:")
                        st.markdown(res_text)
                        play_text_to_speech(res_text)

                    except Exception as e:
                        st.error(f"‚ùå L·ªói khi ph√¢n t√≠ch tin t·ª©c: {e}")
                        st.info(
                            "üí° N·∫øu l·ªói ti·∫øp di·ªÖn, h√£y th·ª≠ ch·ªçn model `gemini-1.5-flash` ·ªü thanh b√™n tr√°i."
                        )

    # ==============================
    # 2) CH·∫æ ƒê·ªò: T√ìM T·∫ÆT S√ÅCH / T√ÄI LI·ªÜU
    # ==============================
    else:
        st.subheader("üìö T√≥m t·∫Øt S√°ch / T√†i li·ªáu")
        txt_input = st.text_area(
            "D√°n n·ªôi dung, ho·∫∑c ch·ªâ c·∫ßn upload file ·ªü thanh b√™n tr√°i:",
            key="news_text_area",
        )
        content = file_content if file_content is not None else txt_input

        if st.button("üìö T√≥m t·∫Øt", key="news_summary_btn") and content:
            with st.spinner("ƒêang t√≥m t·∫Øt n·ªôi dung..."):
                try:
                    model = genai.GenerativeModel(
                        current_model_name,
                        system_instruction=expert_instruction,
                    )

                    if isinstance(content, Image.Image):
                        request = [
                            "Ch·∫ø ƒë·ªô: T√ìM T·∫ÆT S√ÅCH/T√ÄI LI·ªÜU.\n"
                            "H√£y t√≥m t·∫Øt n·ªôi dung ch√≠nh c·ªßa h√¨nh ·∫£nh/t√†i li·ªáu sau, tr√¨nh b√†y d·∫°ng g·∫°ch ƒë·∫ßu d√≤ng d·ªÖ hi·ªÉu cho ng∆∞·ªùi Vi·ªát:",
                            content,
                        ]
                    else:
                        request = [
                            "Ch·∫ø ƒë·ªô: T√ìM T·∫ÆT S√ÅCH/T√ÄI LI·ªÜU.\n"
                            "H√£y t√≥m t·∫Øt n·ªôi dung sau theo ƒë√∫ng quy tr√¨nh b·∫°n ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh "
                            "(√Ω ch√≠nh, ph√¢n t√≠ch ng·∫Øn, t·ªïng k·∫øt 3‚Äì5 √Ω quan tr·ªçng):\n\n"
                            f"{content}"
                        ]

                    res_text = model.generate_content(request).text
                    st.markdown(res_text)
                    play_text_to_speech(res_text)

                except Exception as e:
                    st.error(f"‚ùå L·ªói khi t√≥m t·∫Øt t√†i li·ªáu: {e}")
# -------------------------------------------------------------
# C√ÅC CHUY√äN GIA THEO NG√ÄNH (CHUNG CHO T·∫§T C·∫¢ MENU C√íN L·∫†I)
# Bao g·ªìm: ‚ú® Tr·ª£ L√Ω ƒêa Lƒ©nh V·ª±c, üé® Media, Office, Ki·∫øn tr√∫c, Lu·∫≠t, Kinh doanh...
# -------------------------------------------------------------
else:
    st.header(menu)

    # L·∫•y c·∫•u h√¨nh chuy√™n gia t·ª´ prompts.py
    expert_instruction = get_expert_prompt(menu)

    # Tu·ª≥ ch·ªânh th√™m cho Gi√°o d·ª•c (ch·ªçn b·ªô s√°ch / vai tr√≤)
    system_append = ""
    if menu == "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o":
        c1, c2 = st.columns(2)
        sach = c1.selectbox(
            "B·ªô s√°ch:",
            ["C√°nh Di·ªÅu", "K·∫øt N·ªëi Tri Th·ª©c", "Ch√¢n Tr·ªùi S√°ng T·∫°o"],
        )
        role = c2.radio(
            "Vai tr√≤:",
            ["H·ªçc sinh", "Gi√°o vi√™n", "Ph·ª• huynh"],
            horizontal=True,
        )
        system_append = f"\n(B·ªô s√°ch: {sach}, ƒê·ªëi t∆∞·ª£ng: {role})."

    # Upload file ri√™ng cho t·ª´ng c√¢u h·ªèi (n·∫±m trong khu chat, d·ªÖ nh√¨n)
    st.markdown("**üìé ƒê√≠nh k√®m t√†i li·ªáu cho c√¢u h·ªèi n√†y (t√πy ch·ªçn):**")
    chat_uploaded_file = st.file_uploader(
        "Ch·ªçn file cho c√¢u h·ªèi (·∫£nh/PDF/Word/Excel...):",
        type=["png", "jpg", "jpeg", "pdf", "txt", "csv", "xlsx", "docx"],
        label_visibility="collapsed",
        key=f"chat_uploader_{menu}",
    )
    chat_file_content = None
    if chat_uploaded_file is not None:
        chat_file_content = process_uploaded_file(chat_uploaded_file)

    # L∆∞u l·ªãch s·ª≠ chat theo t·ª´ng menu chuy√™n gia
    if "history" not in st.session_state:
        st.session_state.history = {}

    if menu not in st.session_state.history:
        st.session_state.history[menu] = [
            {
                "role": "assistant",
                "content": (
                    f"Xin ch√†o! T√¥i l√† **chuy√™n gia {menu}** trong h·ªá sinh th√°i Rin.Ai. "
                    "B·∫°n h√£y m√¥ t·∫£ th·∫≠t r√µ y√™u c·∫ßu, b·ªëi c·∫£nh v√† m·ª•c ti√™u, t√¥i s·∫Ω h·ªó tr·ª£ theo ƒë√∫ng vai tr√≤ & quy tr√¨nh ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh."
                ),
            }
        ]

    # Hi·ªÉn th·ªã l·∫°i l·ªãch s·ª≠ h·ªôi tho·∫°i
    for msg in st.session_state.history[menu]:
        if msg["role"] == "user":
            with st.chat_message("user"):
                st.markdown(msg["content"])
        else:
            # ·∫®n ph·∫ßn PROMPT_2D / 3D khi hi·ªÉn th·ªã, ch·ªâ d√πng n·ªôi b·ªô
            clean_show = re.sub(
                r"###PROMPT_[23]D###.*?###END_PROMPT###",
                "",
                msg["content"],
                flags=re.DOTALL,
            )
            if clean_show.strip():
                with st.chat_message("assistant"):
                    st.markdown(clean_show)

    # √î nh·∫≠p chat
    user_prompt = st.chat_input("G·ª≠i y√™u c·∫ßu cho chuy√™n gia...")

    if user_prompt:
        # X√°c ƒë·ªãnh file s·∫Ω d√πng cho c√¢u h·ªèi n√†y
        used_file_content = (
            chat_file_content if chat_file_content is not None else file_content
        )
        used_file_name = None
        if chat_uploaded_file is not None:
            used_file_name = chat_uploaded_file.name
        elif uploaded_file is not None and file_content is not None:
            used_file_name = uploaded_file.name

        # Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng
        with st.chat_message("user"):
            st.markdown(user_prompt)
            if used_file_name:
                st.caption(f"üìé ƒê√≠nh k√®m: {used_file_name}")

        st.session_state.history[menu].append(
            {"role": "user", "content": user_prompt}
        )

        # G·ªçi model theo ƒë√∫ng chuy√™n gia
        with st.chat_message("assistant"):
            with st.spinner(f"Chuy√™n gia ({current_model_name}) ƒëang ph√¢n t√≠ch..."):
                try:
                    final_prompt = user_prompt + system_append

                    # Chu·∫©n b·ªã payload cho Gemini: n·∫øu c√≥ file th√¨ g·∫Øn th√™m
                    if used_file_content is not None:
                        if isinstance(used_file_content, Image.Image):
                            message_payload = [final_prompt, used_file_content]
                        else:
                            final_prompt += (
                                "\n\n=== FILE DATA (t√≥m t·∫Øt n·ªôi dung ng∆∞·ªùi d√πng g·ª≠i) ===\n"
                                f"{used_file_content}\n"
                                "===================================================="
                            )
                            message_payload = [final_prompt]
                    else:
                        message_payload = [final_prompt]

                    # T·∫°o model & start_chat ƒë·ªÉ c√≥ memory trong t·ª´ng l·∫ßn h·ªèi
                    model = get_model(current_model_name)
                    chat = model.start_chat(
                        system_instruction=expert_instruction,
                        history=[],
                    )
                    response = chat.send_message(message_payload)
                    full_txt = response.text or ""

                    # T√°ch PROMPT_2D / 3D (n·∫øu l√† chuy√™n gia Ki·∫øn tr√∫c)
                    p2d = re.search(
                        r"###PROMPT_2D###(.*?)###END_PROMPT###",
                        full_txt,
                        re.DOTALL,
                    )
                    p3d = re.search(
                        r"###PROMPT_3D###(.*?)###END_PROMPT###",
                        full_txt,
                        re.DOTALL,
                    )
                    txt_show = re.sub(
                        r"###PROMPT_[23]D###.*?###END_PROMPT###",
                        "",
                        full_txt,
                        flags=re.DOTALL,
                    )

                    # Hi·ªÉn th·ªã n·ªôi dung tr·∫£ l·ªùi ch√≠nh
                    st.markdown(txt_show.strip())

                    # N·∫øu c√≥ prompt v·∫Ω 2D/3D ‚Üí demo th√™m ·∫£nh minh ho·∫° (tu·ª≥ ch·ªçn)
                    if p2d or p3d:
                        st.divider()
                        col_a, col_b = st.columns(2)
                        if p2d:
                            with col_a:
                                st.image(
                                    generate_image_url(
                                        "Blueprint floor plan. " + p2d.group(1)
                                    ),
                                    caption="B·∫£n v·∫Ω 2D (demo AI)",
                                )
                        if p3d:
                            with col_b:
                                st.image(
                                    generate_image_url(
                                        "Architecture render 8k. " + p3d.group(1)
                                    ),
                                    caption="Ph·ªëi c·∫£nh 3D (demo AI)",
                                )

                    # L∆∞u v√†o l·ªãch s·ª≠
                    st.session_state.history[menu].append(
                        {"role": "assistant", "content": full_txt}
                    )
                    # Gi·ªõi h·∫°n l·ªãch s·ª≠ ƒë·ªÉ tr√°nh qu√° d√†i
                    if len(st.session_state.history[menu]) > 40:
                        st.session_state.history[menu] = st.session_state.history[
                            menu
                        ][-40:]

                except Exception as e:
                    st.error(f"‚ùå L·ªói khi chuy√™n gia tr·∫£ l·ªùi: {e}")
                    st.warning(
                        "‚ö†Ô∏è N·∫øu g·∫∑p l·ªói, h√£y th·ª≠ ƒë·ªïi sang model 'gemini-1.5-flash' ·ªü thanh b√™n tr√°i."
                    )


