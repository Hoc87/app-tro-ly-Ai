import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import io
import re
import requests 
from PIL import Image
import PyPDF2
import pandas as pd

# --- IMPORT FILE PROMPTS (G·ªåI TR·ª¢ L√ù T·ª™ FILE B√äN KIA) ---
from prompts import get_expert_prompt

# =============================================================================
# 1. C·∫§U H√åNH & H√ÄM H·ªñ TR·ª¢
# =============================================================================

st.set_page_config(page_title="Rin.Ai - Si√™u Tr·ª£ L√Ω AI", page_icon="üíé", layout="wide")

def process_uploaded_file(uploaded_file):
    if uploaded_file is None: return None
    try:
        if uploaded_file.type.startswith('image'):
            return Image.open(uploaded_file)
        elif uploaded_file.type == "application/pdf":
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages: text += page.extract_text()
            return text
        elif "excel" in uploaded_file.type or "spreadsheet" in uploaded_file.type or "csv" in uploaded_file.type:
            if "csv" in uploaded_file.type: df = pd.read_csv(uploaded_file)
            else: df = pd.read_excel(uploaded_file)
            return df.to_string()
        else: return uploaded_file.getvalue().decode("utf-8")
    except Exception as e: return f"L·ªói ƒë·ªçc file: {e}"

def clean_text_for_tts(text):
    if not text: return ""
    clean = re.sub(r'###PROMPT_[23]D###.*?###END_PROMPT###', '', text, flags=re.DOTALL)
    clean = re.sub(r'\([^)]*\)', '', clean)
    clean = re.sub(r'\[[^]]*\]', '', clean)
    clean = clean.replace('*', '').replace('#', '').replace('`', '')
    return clean.strip()

def play_text_to_speech(text_content, speed_slow=False):
    try:
        text_to_read = clean_text_for_tts(text_content)
        if len(text_to_read) < 5: return
        tts = gTTS(text=text_to_read, lang='vi', slow=speed_slow)
        audio_bytes = io.BytesIO()
        tts.write_to_fp(audio_bytes)
        st.audio(audio_bytes, format='audio/mp3')
        status = "üê¢ ƒêang ƒë·ªçc ch·∫≠m..." if speed_slow else "üêá ƒêang ƒë·ªçc t·ªëc ƒë·ªô th∆∞·ªùng..."
        st.caption(f"üîä {status}")
    except: pass

def generate_image_url(prompt):
    clean_prompt = prompt.replace(" ", "%20")
    return f"https://image.pollinations.ai/prompt/{clean_prompt}?nologo=true&model=turbo"

@st.cache_resource
def get_best_model(api_key):
    genai.configure(api_key=api_key)
    try:
        models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        priority = ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-pro"]
        for p in priority:
            for m in models:
                if p in m: return m
        return "gemini-pro"
    except: return None

# =============================================================================
# 2. GIAO DI·ªÜN CH√çNH
# =============================================================================

with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/12222/12222588.png", width=80)
    st.title("RIN.AI PRO")
    st.caption("Developed by Mr. H·ªçc")
    st.divider()
    
    # --- KEY ---
    st.subheader("üîë T√†i kho·∫£n s·ª≠ d·ª•ng")
    key_option = st.radio("Ch·∫ø ƒë·ªô:", ["üöÄ D√πng Mi·ªÖn Ph√≠", "üíé Nh·∫≠p Key C·ªßa B·∫°n"], label_visibility="collapsed")
    final_key = None
    if key_option == "üöÄ D√πng Mi·ªÖn Ph√≠":
        try:
            final_key = st.secrets["GOOGLE_API_KEY"]
            st.success("‚úÖ ƒê√£ k·∫øt n·ªëi Server")
        except: st.error("‚ùå Ch∆∞a c·∫•u h√¨nh Key chung")
    else: 
        st.info("Nh·∫≠p Google API Key c·ªßa b·∫°n:")
        final_key = st.text_input("API Key:", type="password")
        if final_key: st.success("‚úÖ ƒê√£ nh·∫≠n Key")
    
    st.divider()

    # --- LI√äN K·∫æT NGO√ÄI ---
    st.info("ü§ñ AI N√¢ng Cao & ChatGPT")
    st.link_button("üëâ Tr·ª£ L√Ω ChatGPT (App Ri√™ng)", "https://chatgpt.com/") 
    st.divider()
    
    st.subheader("üåê H·ªá Sinh Th√°i Google AI")
    with st.expander("M·ªü c√¥ng c·ª• Google"):
        st.link_button("üìö NotebookLM (T√†i li·ªáu)", "https://notebooklm.google.com/")
        st.link_button("üõ†Ô∏è Google AI Studio", "https://aistudio.google.com/")
        st.link_button("üé® ImageFX (T·∫°o ·∫£nh)", "https://aitestkitchen.withgoogle.com/tools/image-fx")
        st.link_button("üé• VideoFX (T·∫°o Video)", "https://aitestkitchen.withgoogle.com/tools/video-fx")
    
    st.divider()
    
    # --- UPLOAD ---
    st.subheader("üìé T√†i li·ªáu ƒë√≠nh k√®m")
    uploaded_file = st.file_uploader("Upload...", type=['png', 'jpg', 'pdf', 'txt', 'csv', 'xlsx'], label_visibility="collapsed")
    file_content = process_uploaded_file(uploaded_file)
    if file_content: st.info(f"‚úÖ ƒê√£ ƒë·ªçc: {uploaded_file.name}")
    
    st.divider()

    # 3. MENU CH·ª®C NƒÇNG (ƒê√É S·ª¨A L·ªñI D√çNH D√íNG)
    st.subheader("üìÇ Ch·ªçn Chuy√™n Gia")
    menu = st.radio("Lƒ©nh v·ª±c:", [
        "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu", 
        "‚ú® Tr·ª£ L√Ω ƒêa Lƒ©nh V·ª±c (Chung)",
        "üèõÔ∏è D·ªãch V·ª• H√†nh Ch√≠nh C√¥ng",
        "üèõÔ∏è Tr·ª£ L√Ω C√°n b·ªô ·ª¶y ban (X√£/Ph∆∞·ªùng/TP)", # <--- NH·ªö D·∫§U PH·∫®Y N√ÄY
        "üèóÔ∏è Ki·∫øn Tr√∫c - N·ªôi Th·∫•t - X√¢y D·ª±ng",     # <--- ƒê√É T√ÅCH RA TH√ÄNH D√íNG RI√äNG
        "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch", 
        "üé® Thi·∫øt K·∫ø & Media (·∫¢nh/Video/Voice)", 
        "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o", 
        "üé• Chuy√™n Gia Video Google Veo",
        "üëî Nh√¢n S·ª± - Tuy·ªÉn D·ª•ng - CV",
        "‚öñÔ∏è Lu·∫≠t - H·ª£p ƒê·ªìng - H√†nh Ch√≠nh",
        "üí∞ Kinh Doanh & Marketing", 
        "üè¢ Gi√°m ƒê·ªëc & Qu·∫£n Tr·ªã (CEO)",
        "üõí TMƒêT (Shopee/TikTok Shop)",
        "üíª L·∫≠p Tr√¨nh - Freelancer - Digital",
        "‚ù§Ô∏è Y T·∫ø - S·ª©c Kh·ªèe - Gym",
        "‚úàÔ∏è Du L·ªãch - L·ªãch Tr√¨nh - Vi Vu",
        "üß† T√¢m L√Ω - C·∫£m X√∫c - Tinh Th·∫ßn",
        "üçΩÔ∏è Nh√† H√†ng - F&B - ·∫®m Th·ª±c",
        "üì¶ Logistic - V·∫≠n H√†nh - Kho B√£i",
        "üìä K·∫ø To√°n - B√°o C√°o - S·ªë Li·ªáu",
        "üé§ S·ª± Ki·ªán - MC - H·ªôi Ngh·ªã",
        "üè† B·∫•t ƒê·ªông S·∫£n & Xe Sang"
    ])

# --- LOGIC ---

if menu == "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu":
    st.title("üíé H·ªá Sinh Th√°i AI Th·ª±c Chi·∫øn - Rin.Ai")
    st.markdown("""
    ### üöÄ Rin.Ai - Super App ƒêa Ph∆∞∆°ng Ti·ªán
    Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi phi√™n b·∫£n Rin.Ai PRO.
    * **Ki·∫øn Tr√∫c S∆∞ AI:** T·ª± v·∫Ω 2D/3D.
    * **Tr·ª£ L√Ω ·ª¶y Ban:** So·∫°n th·∫£o vƒÉn b·∫£n chu·∫©n Ngh·ªã ƒë·ªãnh 30.
    * **Media Pro:** T·∫°o Prompt Video & Voice AI c·∫£m x√∫c.
    
    ---
    ### üë®‚Äçüè´ Li√™n h·ªá ƒë√†o t·∫°o & H·ª£p t√°c:
    ## **Mr. H·ªçc** - üìû Hotline/Zalo: **0901 108 788**
    """)

elif not final_key:
    st.warning("üëã Vui l√≤ng nh·∫≠p Key b√™n tay tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

else:
    best_model = get_best_model(final_key)
    genai.configure(api_key=final_key)

    # 1. MODULE TIN T·ª®C
    if menu == "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch":
        st.header("üì∞ Chuy√™n Gia Tri Th·ª©c")
        task = st.radio("Ch·∫ø ƒë·ªô:", ["üîé Tin T·ª©c", "üìö T√≥m t·∫Øt S√°ch"], horizontal=True)
        if task == "üîé Tin T·ª©c":
            topic = st.text_input("Ch·ªß ƒë·ªÅ:")
            if st.button("üîé T·ªïng h·ª£p"):
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    model = genai.GenerativeModel(best_model)
                    res = model.generate_content(f"T·ªïng h·ª£p tin t·ª©c m·ªõi nh·∫•t v·ªÅ: {topic}").text
                    st.markdown(res)
                    play_text_to_speech(res)
        else:
            txt = st.text_area("VƒÉn b·∫£n:")
            inp = file_content if file_content else txt
            if st.button("üìö T√≥m t·∫Øt") and inp:
                with st.spinner("ƒêang ƒë·ªçc..."):
                    model = genai.GenerativeModel(best_model)
                    res = model.generate_content(f"T√≥m t·∫Øt: {inp}").text
                    st.markdown(res)
                    play_text_to_speech(res)

    # 2. MODULE MEDIA
    elif menu == "üé® Thi·∫øt K·∫ø & Media (·∫¢nh/Video/Voice)":
        st.header("üé® Studio ƒêa Ph∆∞∆°ng Ti·ªán")
        mode = st.radio("C√¥ng c·ª•:", ["üñºÔ∏è T·∫°o ·∫¢nh", "üé¨ T·∫°o Video", "üéôÔ∏è Voice AI"], horizontal=True)
        
        if mode == "üñºÔ∏è T·∫°o ·∫¢nh":
            desc = st.text_area("M√¥ t·∫£ ·∫£nh:")
            if st.button("üé® V·∫Ω"):
                with st.spinner("ƒêang v·∫Ω..."):
                    model = genai.GenerativeModel(best_model)
                    p_en = model.generate_content(f"Translate to English prompt: {desc}").text
                    st.image(generate_image_url(p_en))
        
        elif mode == "üé¨ T·∫°o Video":
            idea = st.text_area("√ù t∆∞·ªüng video:")
            if st.button("üé• T·∫°o Prompt"):
                model = genai.GenerativeModel(best_model)
                p = model.generate_content(f"Create English Video Prompt (Sora/Runway) for: {idea}. Structure: [Subject] [Movement] [Style]").text
                st.code(p)

        elif mode == "üéôÔ∏è Voice AI":
            c1, c2 = st.columns(2)
            is_slow = c1.checkbox("üê¢ ƒê·ªçc ch·∫≠m", value=False)
            tone = c2.selectbox("C·∫£m x√∫c:", ["Truy·ªÅn c·∫£m", "Vui t∆∞∆°i", "Nghi√™m t√∫c", "H√†o h·ª©ng", "Bu·ªìn"])
            topic = st.text_area("N·ªôi dung:")
            if st.button("üéôÔ∏è T·∫°o & ƒê·ªçc"):
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    model = genai.GenerativeModel(best_model)
                    res = model.generate_content(f"Vi·∫øt k·ªãch b·∫£n ng·∫Øn. C·∫£m x√∫c: {tone}. Ch·ªß ƒë·ªÅ: {topic}. Ghi ch√∫ di·ªÖn xu·∫•t trong ngo·∫∑c ƒë∆°n.").text
                    st.markdown(res)
                    play_text_to_speech(res, is_slow)

    # 3. MODULE CHUY√äN GIA (CHATBOTS) - G·ªåI T·ª™ FILE PROMPTS
    else:
        st.header(menu)
        
        # --- G·ªåI H√ÄM L·∫§Y PROMPT T·ª™ FILE PROMPTS.PY ---
        expert_instruction = get_expert_prompt(menu)
        
        # Logic Gi√°o d·ª•c
        edu_append = ""
        if menu == "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o":
            sach = st.selectbox("S√°ch:", ["C√°nh Di·ªÅu", "KNTT", "CTST"])
            edu_append = f". S√°ch: {sach}."

        # Chat History
        if "history" not in st.session_state: st.session_state.history = {}
        if menu not in st.session_state.history:
            st.session_state.history[menu] = []
            st.session_state.history[menu].append({"role": "assistant", "content": "Xin ch√†o! T√¥i l√† chuy√™n gia lƒ©nh v·ª±c n√†y. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"})

        # Hi·ªán l·ªãch s·ª≠ (Text clean)
        for msg in st.session_state.history[menu]:
             if msg["role"] == "user":
                 with st.chat_message("user"): st.markdown(msg["content"])
             else:
                 clean_show = re.sub(r'###PROMPT_[23]D###.*?###END_PROMPT###', '', msg["content"], flags=re.DOTALL)
                 if clean_show.strip():
                     with st.chat_message("assistant"): st.markdown(clean_show)

        # Input m·ªõi
        if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi..."):
            with st.chat_message("user"):
                st.markdown(prompt)
                if file_content: st.caption("üìé [C√≥ file]")
            st.session_state.history[menu].append({"role": "user", "content": prompt})

            with st.chat_message("assistant"):
                with st.spinner("Chuy√™n gia ƒëang tr·∫£ l·ªùi..."):
                    try:
                        full_p = [prompt + edu_append]
                        if file_content: full_p.append(f"FILE:\n{file_content}")
                        
                        model = genai.GenerativeModel(best_model, system_instruction=expert_instruction)
                        response = model.generate_content(full_p)
                        full_txt = response.text

                        # T√°ch ·∫£nh & Text
                        p2d = re.search(r'###PROMPT_2D###(.*?)###END_PROMPT###', full_txt, re.DOTALL)
                        p3d = re.search(r'###PROMPT_3D###(.*?)###END_PROMPT###', full_txt, re.DOTALL)
                        txt_show = re.sub(r'###PROMPT_[23]D###.*?###END_PROMPT###', '', full_txt, flags=re.DOTALL)
                        
                        st.markdown(txt_show.strip())
                        
                        if p2d or p3d:
                            st.divider()
                            c_a, c_b = st.columns(2)
                            if p2d:
                                with c_a: st.image(generate_image_url("Blueprint. " + p2d.group(1)), caption="B·∫£n v·∫Ω 2D")
                            if p3d:
                                with c_b: st.image(generate_image_url("Architecture render. " + p3d.group(1)), caption="Ph·ªëi c·∫£nh 3D")
                        
                        st.session_state.history[menu].append({"role": "assistant", "content": full_txt})
                    except Exception as e: st.error(f"L·ªói: {e}")
