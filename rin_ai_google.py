import io
import re
from datetime import datetime

import docx
import google.generativeai as genai
import pandas as pd
import PyPDF2
import streamlit as st
from gtts import gTTS
from PIL import Image

from prompts import get_expert_prompt

# -------------------------------------------------------------
# C·∫§U H√åNH CHUNG
# -------------------------------------------------------------

st.set_page_config(
    page_title="Rin.Ai - Si√™u Tr·ª£ L√Ω AI",
    page_icon="üíé",
    layout="wide",
)

# ·∫®n b·ªõt n√∫t c·ªßa Streamlit nh∆∞ng KH√îNG ƒë·ª•ng v√†o header / toolbar / sidebar
st.markdown(
    """
    <style>
    /* 1. ·∫®n n√∫t Deploy + 2 icon (edit, GitHub) ·ªü g√≥c ph·∫£i */
    .stDeployButton {display:none;}
    [data-testid="StyledFullScreenButton"] {display:none;}   /* icon c√¢y b√∫t */
    [data-testid="baseLinkButton-secondary"] {display:none;} /* icon GitHub */
    
    /* ·∫®n thanh header c√≥ ch·ªØ Fork + icon GitHub */
    header[data-testid="stHeader"] {
        display: none !important;
    }

    /* ·∫®n c√°c badge / icon n·ªïi d∆∞·ªõi ƒë√°y app (2 icon ·ªü mobile) */
    a[class^="viewerBadge_link__"],
    div[class^="viewerBadge_container__"],
    div[data-testid="stStatusWidget"] {
        display: none !important;
    }

    /* 2. ·∫®n menu m·∫∑c ƒë·ªãnh & footer, nh∆∞ng KH√îNG ·∫©n header */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    
    /* 3. ·∫®N THANH TOOLBAR (N∆°i ch·ª©a n√∫t C√¢y b√∫t v√† Con m√®o) */
    [data-testid="stToolbar"] {
        visibility: hidden !important; 
        height: 0px; /* Thu nh·ªè chi·ªÅu cao ƒë·ªÉ kh√¥ng chi·∫øm ch·ªó */
    }
    
    /* ·∫®n th√™m Header Action Elements ƒë·ªÉ ch·∫Øc ch·∫Øn m·∫•t h·∫≥n */
    [data-testid="stHeaderActionElements"] {
        display: none !important;
    }

    /* 4. ƒê·∫£m b·∫£o header, toolbar, n√∫t m≈©i t√™n sidebar LU√îN HI·ªÜN */
    header {visibility: visible !important;}
    [data-testid="stToolbar"] {visibility: visible !important;}
    [data-testid="stSidebarCollapsedControl"] {
        visibility: visible !important;
        display: flex !important;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# -------------------------------------------------------------
# H√ÄM H·ªñ TR·ª¢
# -------------------------------------------------------------

def process_uploaded_file(uploaded_file):
    if uploaded_file is None:
        return None
    try:
        file_type = uploaded_file.type or ""
        file_name = uploaded_file.name.lower()

        if file_type.startswith("image"):
            return Image.open(uploaded_file)

        if file_type == "application/pdf" or file_name.endswith(".pdf"):
            pdf_reader = PyPDF2.PdfReader(uploaded_file)
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() or ""
            return text

        if (
            "excel" in file_type
            or "spreadsheet" in file_type
            or file_name.endswith(".csv")
            or file_name.endswith(".xlsx")
        ):
            if file_name.endswith(".csv"):
                df = pd.read_csv(uploaded_file)
            else:
                df = pd.read_excel(uploaded_file)
            return df.to_string(index=False)

        if file_name.endswith(".docx"):
            d = docx.Document(uploaded_file)
            text = "\n".join(p.text for p in d.paragraphs)
            return text

        raw = uploaded_file.getvalue()
        try:
            return raw.decode("utf-8")
        except UnicodeDecodeError:
            return raw.decode("latin-1")

    except Exception as e:
        return f"L·ªói ƒë·ªçc file: {e}"


def clean_text_for_tts(text: str) -> str:
    if not text:
        return ""
    clean = re.sub(
        r"###PROMPT_[23]D###.*?###END_PROMPT###",
        "",
        text,
        flags=re.DOTALL,
    )
    clean = clean.replace("**", "")
    clean = re.sub(r"`+", "", clean)
    clean = re.sub(r"\n{2,}", "\n", clean)
    return clean.strip()


def play_text_to_speech(text_content: str, speed_slow: bool = False):
    try:
        text_to_read = clean_text_for_tts(text_content)
        if len(text_to_read) < 5:
            return
        tts = gTTS(text=text_to_read, lang="vi", slow=speed_slow)
        audio_bytes = io.BytesIO()
        tts.write_to_fp(audio_bytes)
        audio_bytes.seek(0)
        st.audio(audio_bytes, format="audio/mp3")
        status = "üê¢ ƒêang ƒë·ªçc ch·∫≠m..." if speed_slow else "üêá ƒêang ƒë·ªçc t·ªëc ƒë·ªô th∆∞·ªùng..."
        st.caption(f"üîä {status}")
    except Exception:
        pass


def generate_image_url(prompt: str) -> str:
    clean_prompt = prompt.replace(" ", "%20")
    return f"https://image.pollinations.ai/prompt/{clean_prompt}?nologo=true&model=turbo"


@st.cache_resource(show_spinner=False)
def get_available_models(api_key: str):
    try:
        genai.configure(api_key=api_key)
        models = list(genai.list_models())
        names = [
            m.name
            for m in models
            if "generateContent" in getattr(m, "supported_generation_methods", [])
        ]
        # L·ªçc model an to√†n: lo·∫°i tts / speech / embed
        candidates = [
            n
            for n in names
            if "gemini" in n.lower()
            and (
                "1.5" in n
                or "2.0" in n
                or "2.5" in n
                or "pro" in n.lower()
                or "flash" in n.lower()
            )
            and "tts" not in n.lower()
            and "speech" not in n.lower()
            and "embed" not in n.lower()
        ]
        if not candidates:
            candidates = names or ["gemini-1.5-flash"]

        def sort_key(x: str):
            return (
                "flash" not in x.lower(),
                "pro" not in x.lower(),
                "2.5" not in x,
                "2.0" not in x,
                "1.5" not in x,
            )

        candidates.sort(key=sort_key)
        return candidates
    except Exception:
        return ["gemini-1.5-flash"]

        if not candidates:
            candidates = names or ["gemini-1.5-flash"]

        def sort_key(x: str):
            return (
                "flash" not in x.lower(),
                "pro" not in x.lower(),
                "2.5" not in x,
                "2.0" not in x,
                "1.5" not in x,
            )

        candidates.sort(key=sort_key)
        return candidates
    except Exception:
        return ["gemini-1.5-flash"]


def get_model(model_name: str):
    return genai.GenerativeModel(model_name)


# -------------------------------------------------------------
# SIDEBAR
# -------------------------------------------------------------

with st.sidebar:
    st.image(
        "https://cdn-icons-png.flaticon.com/512/12222/12222588.png",
        width=80,
    )
    st.title("RIN.AI PRO")
    st.caption("Developed by Mr. H·ªçc")
    st.divider()

    # ---- T√ÄI KHO·∫¢N & C·∫§U H√åNH ----
    st.subheader("üîë T√†i kho·∫£n & C·∫•u h√¨nh")
    key_option = st.radio(
        "Ch·∫ø ƒë·ªô:",
        ["üöÄ D√πng Mi·ªÖn Ph√≠", "üíé Nh·∫≠p Key C·ªßa B·∫°n"],
        label_visibility="collapsed",
    )

    final_key = None
    if key_option == "üöÄ D√πng Mi·ªÖn Ph√≠":
        try:
            final_key = st.secrets["GOOGLE_API_KEY"]
            st.success("‚úÖ ƒê√£ k·∫øt n·ªëi Server chung")
        except Exception:
            st.error("‚ùå Ch∆∞a c·∫•u h√¨nh Key chung tr√™n server.")
    else:
        st.info("Nh·∫≠p Google API Key:")
        st.markdown(
            "[üëâ B·∫•m v√†o ƒë√¢y ƒë·ªÉ l·∫•y Key mi·ªÖn ph√≠](https://aistudio.google.com/app/apikey)"
        )
        final_key = st.text_input("D√°n Key v√†o ƒë√¢y:", type="password")
        if final_key:
            st.success("‚úÖ ƒê√£ nh·∫≠n Key c√° nh√¢n")

    # ---- CH·ªåN MODEL (T·ª∞ ƒê·ªòNG + N√ÇNG CAO) ----
    if final_key:
        available_models = get_available_models(final_key)
        recommended_model = available_models[0]

        advanced_model_choice = st.checkbox(
            "‚öôÔ∏è B·∫≠t ch·∫ø ƒë·ªô ch·ªçn model n√¢ng cao",
            value=False,
        )

        if advanced_model_choice:
            selected_model_display = st.selectbox(
                "üß† Ch·ªçn b·ªô n√£o AI:",
                available_models,
                index=0,
            )
            current_model_name = selected_model_display
            st.caption(f"ƒêang d√πng model: `{current_model_name}` (t√πy ch·ªânh)")
        else:
            current_model_name = recommended_model
            st.caption(f"ƒêang d√πng model khuy·∫øn ngh·ªã: `{current_model_name}`")

    st.divider()

    # ---- C√îNG C·ª§ M·ªû R·ªòNG ----
    st.subheader("üî• C√¥ng C·ª• M·ªü R·ªông")
    st.link_button(
        "ü§ñ Danh s√°ch Tr·ª£ L√Ω AI ChatGPT",
        "https://chatgpt.com/g/g-69004bb8428481918ecf4ade89a9216c-rin-ai-center-trung-tam-tro-ly-ai",
    )
    with st.expander("üåê Google AI Tools (Full)"):
        st.link_button("üíé Gemini Chat", "https://gemini.google.com/")
        st.link_button("üìö NotebookLM", "https://notebooklm.google.com/")
        st.link_button("üõ†Ô∏è AI Studio", "https://aistudio.google.com/")
        st.link_button(
            "üé® ImageFX",
            "https://aitestkitchen.withgoogle.com/tools/image-fx",
        )
        st.link_button(
            "üé• VideoFX",
            "https://aitestkitchen.withgoogle.com/tools/video-fx",
        )
        st.link_button(
            "üéµ MusicFX",
            "https://aitestkitchen.withgoogle.com/tools/music-fx",
        )

    with st.expander("üìù VƒÉn ph√≤ng (Workspace)"):
        st.link_button("Google Docs", "https://docs.google.com/")
        st.link_button("Google Sheets", "https://sheets.google.com/")

    st.divider()

    # ---- UPLOAD FILE TO√ÄN PHI√äN ----
    st.subheader("üìé ƒê√≠nh K√®m T√†i Li·ªáu (To√†n phi√™n)")
    uploaded_file = st.file_uploader(
        "Ch·ªçn file:",
        type=["png", "jpg", "jpeg", "pdf", "txt", "csv", "xlsx", "docx"],
        label_visibility="collapsed",
        key="sidebar_uploader",
    )
    file_content = None
    if uploaded_file:
        file_content = process_uploaded_file(uploaded_file)
        st.success(f"‚úÖ ƒê√£ nh·∫≠n: {uploaded_file.name}")

    st.divider()

    # ---- MENU CHUY√äN GIA ----
    st.subheader("üìÇ Ch·ªçn Chuy√™n Gia (H·ªá sinh th√°i Ai c·ªßa Google")
    menu = st.selectbox(
        "Lƒ©nh v·ª±c h·ªó tr·ª£:",
        [
            "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu",
            "‚ú® Tr·ª£ L√Ω ƒêa Lƒ©nh V·ª±c (Chung)",
            "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch",
            "üé® Thi·∫øt K·∫ø & Media (·∫¢nh/Video/Voice)",
            "üñ•Ô∏è Chuy√™n Gia Tin H·ªçc VƒÉn Ph√≤ng (Office)",
            "üèóÔ∏è Ki·∫øn Tr√∫c - N·ªôi Th·∫•t - X√¢y D·ª±ng",
            "üèõÔ∏è Tr·ª£ L√Ω C√°n b·ªô ·ª¶y ban (X√£/Ph∆∞·ªùng/TP)",
            "üèõÔ∏è D·ªãch V·ª• H√†nh Ch√≠nh C√¥ng",
            "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o",
            "üé• Chuy√™n Gia Video Google Veo",
            "üëî Nh√¢n S·ª± - Tuy·ªÉn D·ª•ng - CV",
            "‚öñÔ∏è Lu·∫≠t - H·ª£p ƒê·ªìng - H√†nh Ch√≠nh",
            "üí∞ Kinh Doanh & Marketing",
            "üè¢ Gi√°m ƒê·ªëc & Qu·∫£n Tr·ªã (CEO)",
            "üõí TMƒêT (Shopee/TikTok Shop)",
            "üíª L·∫≠p Tr√¨nh - Freelancer - Digital",
            "‚ù§Ô∏è Y T·∫ø - S·ª©c Kh·ªèe - Gym",
            "‚úàÔ∏è Du L·ªãch - L·ªãch Tr√¨nh - Vi Vu",
            "üß† T√¢m L√Ω - C·∫£m X√∫c - Tinh Th·∫ßn",
            "üçΩÔ∏è Nh√† H√†ng - F&B - ·∫®m Th·ª±c",
            "üì¶ Logistic - V·∫≠n H√†nh - Kho B√£i",
            "üìä K·∫ø To√°n - B√°o C√°o - S·ªë Li·ªáu",
            "üé§ S·ª± Ki·ªán - MC - H·ªôi Ngh·ªã",
            "üè† B·∫•t ƒê·ªông S·∫£n & Xe Sang",
        ],
    )
# ... (C√°c ph·∫ßn menu b√™n tr√™n gi·ªØ nguy√™n) ...

    st.divider()
    
    # --- KHU V·ª∞C QU·∫¢N TR·ªä VI√äN (ADMIN) ---
    # D√πng Expander ƒë·ªÉ gi·∫•u g·ªçn l·∫°i
    with st.expander("‚öôÔ∏è Admin Control (Ch·ªß s·ªü h·ªØu)"):
        admin_pass = st.text_input("Nh·∫≠p m·∫≠t kh·∫©u Admin:", type="password", key="admin_pass")
        
        # ƒê·∫∑t m·∫≠t kh·∫©u c·ªßa ri√™ng b·∫°n ·ªü ƒë√¢y (V√≠ d·ª•: Hoc87)
        if admin_pass == "Orin": 
            st.success("üîì Ch√†o Mr. H·ªçc! ƒê√£ m·ªü kh√≥a quy·ªÅn Admin.")
            
            st.markdown("---")
            st.write("üëá **B·∫•m v√†o ƒë·ªÉ s·ª≠a code ngay:**")
            
            # Link ƒë·∫øn file ch√≠nh
            st.link_button("üìù S·ª≠a file rin_ai_google.py", "https://github.com/Hoc87/app-tro-ly-Ai/edit/main/rin_ai_google.py")
            
            # Link ƒë·∫øn file Prompt
            st.link_button("üß† S·ª≠a file prompts.py", "https://github.com/Hoc87/app-tro-ly-Ai/edit/main/prompts.py")
            
            # Link ƒë·∫øn file th∆∞ vi·ªán
            st.link_button("üì¶ S·ª≠a requirements.txt", "https://github.com/Hoc87/app-tro-ly-Ai/edit/main/requirements.txt")
            
            st.info("L∆∞u √Ω: Sau khi s·ª≠a tr√™n GitHub v√† Commit, h√£y quay l·∫°i ƒë√¢y F5 ƒë·ªÉ th·∫•y thay ƒë·ªïi.")
        elif admin_pass:
            st.error("Sai m·∫≠t kh·∫©u!")

# =============================================================================
# 3. LOGIC CH√çNH (MAIN APP)
# =============================================================================
# -------------------------------------------------------------
# MAIN
# -------------------------------------------------------------

if not final_key and menu != "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu":
    st.warning("üëã Vui l√≤ng nh·∫≠p Google API Key b√™n tay tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu.")
    st.stop()

if final_key:
    genai.configure(api_key=final_key)

# TRANG CH·ª¶
if menu == "üè† Trang Ch·ªß & Gi·ªõi Thi·ªáu":
    st.title("üíé H·ªá Sinh Th√°i AI Th·ª±c Chi·∫øn - Rin.Ai")
    
    # --- ƒê∆ØA CAM K·∫æT B·∫¢O M·∫¨T L√äN ƒê·∫¶U (NGAY D∆Ø·ªöI TI√äU ƒê·ªÄ) ---
    st.info("""
    üõ°Ô∏è **CAM K·∫æT B·∫¢O M·∫¨T & QUY·ªÄN RI√äNG T∆Ø**
    
    * **An to√†n d·ªØ li·ªáu:** M·ªçi t√†i li·ªáu v√† n·ªôi dung chat ƒë∆∞·ª£c x·ª≠ l√Ω m√£ h√≥a tr·ª±c ti·∫øp tr√™n h·∫° t·∫ßng b·∫£o m·∫≠t ti√™u chu·∫©n qu·ªëc t·∫ø c·ªßa Google & OpenAI.
    * **Ri√™ng t∆∞ tuy·ªát ƒë·ªëi:** Rin.Ai ch·ªâ l√† c√¥ng c·ª• tr·ª£ l√Ω Ai, **KH√îNG** l∆∞u tr·ªØ, **KH√îNG** thu th·∫≠p v√† **KH√îNG** xem ƒë∆∞·ª£c d·ªØ li·ªáu c√° nh√¢n c·ªßa ng∆∞·ªùi d√πng.
    * **Minh b·∫°ch:** B·∫°n l√† ng∆∞·ªùi duy nh·∫•t s·ªü h·ªØu d·ªØ li·ªáu c·ªßa m√¨nh.
    """)
    
    st.markdown("---")
    
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
üíé **Rin.Ai ‚Äì H·ªá Sinh Th√°i AI Th·ª±c Chi·∫øn Cho Ng∆∞·ªùi Vi·ªát**

üëã Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi **Rin.Ai PRO** ƒê∆∞·ª£c nghi√™n c·ª©u, x√¢y d·ª±ng v√† li√™n t·ª•c n√¢ng c·∫•p b·ªüi **Mr. H·ªçc** ‚Äì ng∆∞·ªùi s√°ng l·∫≠p h·ªá sinh th√°i **Rin.Ai**.

Rin.Ai l√† m·ªôt **"Super App" AI** t√≠ch h·ª£p song song hai n·ªÅn t·∫£ng:

- ü§ñ **Google AI Suite**: Gemini, AI Studio, NotebookLM, Imagen, Veo‚Ä¶
- üß† **ChatGPT & h·ªá sinh th√°i OpenAI**

üéØ M·ª•c ti√™u: mang s·ª©c m·∫°nh c·ªßa c√°c m√¥ h√¨nh AI h√†ng ƒë·∫ßu th·∫ø gi·ªõi v√†o **c√¥ng vi·ªác, h·ªçc t·∫≠p v√† t·ª± ƒë·ªông ho√°** h√†ng ng√†y c·ªßa ng∆∞·ªùi Vi·ªát.

---

### üöÄ 1. Cho c√¥ng vi·ªác & kinh doanh

- üñ•Ô∏è H·ªó tr·ª£ **vƒÉn ph√≤ng, b√°o c√°o, Excel/Sheets, bi·ªÉu m·∫´u, h·ª£p ƒë·ªìng, slide thuy·∫øt tr√¨nh**.
- üìà ƒê·ªìng h√†nh c√πng **kinh doanh & marketing**: ch√¢n dung kh√°ch h√†ng, √Ω t∆∞·ªüng n·ªôi dung, k·ªãch b·∫£n video, k·ªãch b·∫£n b√°n h√†ng & chƒÉm s√≥c kh√°ch h√†ng.
- üìã ƒê·ªÅ xu·∫•t **checklist, quy tr√¨nh, m·∫´u template** c√≥ th·ªÉ √°p d·ª•ng ngay v√†o th·ª±c t·∫ø.

### üéì 2. Cho h·ªçc t·∫≠p & ph√°t tri·ªÉn b·∫£n th√¢n

- üìö Gi·∫£i th√≠ch ki·∫øn th·ª©c **t·ª´ ph·ªï th√¥ng ƒë·∫øn k·ªπ nƒÉng ngh·ªÅ** theo c√°ch d·ªÖ hi·ªÉu, nhi·ªÅu v√≠ d·ª•.
- üìÑ T√≥m t·∫Øt nhanh **s√°ch, t√†i li·ªáu, PDF, slide, ghi ch√∫** th√†nh c√°c √Ω ch√≠nh.
- üìù H·ªó tr·ª£ **luy·ªán thi, √¥n t·∫≠p, l√†m b√†i t·∫≠p**, g·ª£i √Ω c√°ch t·ª± h·ªçc th√¥ng minh h∆°n.

### ‚öôÔ∏è 3. T·ª± ƒë·ªông ho√° tr√™n n·ªÅn t·∫£ng Google

- üîß G·ª£i √Ω **Apps Script, c√¥ng th·ª©c, macro** cho Google Docs, Sheets, Slides, Gmail‚Ä¶
- üîÅ Bi·∫øn c√°c thao t√°c l·∫∑p l·∫°i th√†nh **quy tr√¨nh t·ª± ƒë·ªông**, gi·∫£m l·ªói th·ªß c√¥ng.
- üìä G·ª£i √Ω c√°ch **chu·∫©n ho√° d·ªØ li·ªáu, d·ª±ng b√°o c√°o, dashboard** ph·ª•c v·ª• quy·∫øt ƒë·ªãnh nhanh.

---

### ü§ù H·ª£p t√°c x√¢y d·ª±ng Tr·ª£ l√Ω AI ri√™ng

N·∫øu b·∫°n l√† **c√° nh√¢n, doanh nghi·ªáp, trung t√¢m ƒë√†o t·∫°o ho·∫∑c t·ªï ch·ª©c** mu·ªën x√¢y d·ª±ng:

- ü§ñ **Tr·ª£ l√Ω AI mang th∆∞∆°ng hi·ªáu ri√™ng**
- üìÇ T√≠ch h·ª£p **quy tr√¨nh, d·ªØ li·ªáu, t√†i li·ªáu n·ªôi b·ªô** c·ªßa ch√≠nh b·∫°n
- üåê Ho·∫°t ƒë·ªông tr√™n nhi·ªÅu k√™nh (web, mobile, chatbot, n·ªôi b·ªô doanh nghi·ªáp)

‚û°Ô∏è H√£y li√™n h·ªá tr·ª±c ti·∫øp ƒë·ªÉ ƒë∆∞·ª£c t∆∞ v·∫•n & thi·∫øt k·∫ø gi·∫£i ph√°p:

- üë§ **Mr. H·ªçc ‚Äì Founder Rin.Ai**
- üì± **ƒêi·ªán tho·∫°i/Zalo:** **0901108788**
- üìß **Email:** nguyenhoc1010@gmail.com

‚ú® Rin.Ai mong mu·ªën ƒë·ªìng h√†nh c√πng b·∫°n trong h√†nh tr√¨nh **·ª©ng d·ª•ng AI th·ª±c chi·∫øn**, l√†m vi·ªác **nhanh h∆°n ‚Äì th√¥ng minh h∆°n ‚Äì hi·ªáu qu·∫£ h∆°n** m·ªói ng√†y.
üéÅ B·∫°n th·∫•y Rin.Ai h·ªØu √≠ch? **ƒê·ª´ng gi·ªØ cho ri√™ng m√¨nh!** üëâ H√£y chia s·∫ª ƒë∆∞·ªùng link * https://rin-ai.streamlit.app/ * App n√†y ƒë·∫øn **B·∫°n b√® & ƒê·ªìng nghi·ªáp** ƒë·ªÉ c√πng nhau √°p d·ª•ng AI, gi√∫p c√¥ng vi·ªác v√† h·ªçc t·∫≠p tr·ªü n√™n nh·∫π nh√†ng, hi·ªáu qu·∫£ h∆°n.
     *"Th√†nh c√¥ng l√† khi ch√∫ng ta c√πng nhau ti·∫øn b·ªô!"* üöÄ

üëâ **Ti·∫øp theo:** h√£y d√πng **menu b√™n tr√°i** ƒë·ªÉ ch·ªçn **Chuy√™n gia AI** ph√π h·ª£p v·ªõi nhu c·∫ßu c·ªßa b·∫°n v√† b·∫Øt ƒë·∫ßu tr√≤ chuy·ªán ngay b√¢y gi·ªù.
        """)
        st.link_button(
            "üëâ Chat Zalo v·ªõi Mr. H·ªçc",
            "https://zalo.me/0901108788",
        )

    with col2:
        st.image(
            "https://cdn.dribbble.com/users/527451/screenshots/14972580/media/7f4288f6c3eb988a2879a953e5b12854.jpg",
            use_column_width=True,
        )

# ƒê·ªåC B√ÅO & T√ìM T·∫ÆT S√ÅCH
elif menu == "üì∞ ƒê·ªçc B√°o & T√≥m T·∫Øt S√°ch":
    st.header("üì∞ Chuy√™n Gia Tri Th·ª©c & Tin T·ª©c")
    today_str = datetime.now().strftime("%d/%m/%Y")

    # L·∫•y persona g·ªëc t·ª´ prompts.py
    base_instruction = get_expert_prompt(menu)

    # B·ªï sung ng·ªØ c·∫£nh ri√™ng cho ch·∫ø ƒë·ªô TIN T·ª®C
    news_system_instruction = (
        base_instruction
        + f"\n\nNG·ªÆ C·∫¢NH RI√äNG CHO CH·∫æ ƒê·ªò TIN T·ª®C:\n"
          f"- H√¥m nay l√† {today_str} theo h·ªá th·ªëng ·ª©ng d·ª•ng.\n"
          "- B·∫°n c√≥ th·ªÉ d√πng t·ª´ 'h√¥m nay' ƒë·ªÉ n√≥i v·ªÅ ng√†y n√†y, nh∆∞ng ph·∫£i trung th·ª±c r·∫±ng d·ªØ li·ªáu chi ti·∫øt "
          "ch·ªâ c·∫≠p nh·∫≠t t·ªõi kho·∫£ng nƒÉm 2024.\n"
          "- Trong h·ªôi tho·∫°i, ƒë∆∞·ª£c ph√©p h·ªèi T·ªêI ƒêA 1‚Äì2 c√¢u l√†m r√µ, sau ƒë√≥ PH·∫¢I chuy·ªÉn sang t√≥m t·∫Øt & ph√¢n t√≠ch; "
          "kh√¥ng h·ªèi ƒëi h·ªèi l·∫°i c√πng m·ªôt n·ªôi dung.\n"
    )

    mode = st.radio(
        "Ch·∫ø ƒë·ªô:",
        ["üîé Tin T·ª©c Th·ªùi S·ª±", "üìö T√≥m t·∫Øt S√°ch/T√†i li·ªáu"],
        horizontal=True,
        key="news_mode_radio",
    )

    # ==============================
    # 1) CHAT TIN T·ª®C TH·ªúI S·ª∞
    # ==============================
    if mode == "üîé Tin T·ª©c Th·ªùi S·ª±":
        st.subheader("üí¨ Chat Tin T·ª©c Th·ªùi S·ª±")

        # L∆∞u l·ªãch s·ª≠ tin nh·∫Øn hi·ªÉn th·ªã
        if "news_messages" not in st.session_state:
            st.session_state.news_messages = []

        # Kh·ªüi t·∫°o session chat v·ªõi Gemini (gi·ªØ ng·ªØ c·∫£nh qua nhi·ªÅu l∆∞·ª£t)
        if "news_bot" not in st.session_state:
            model = genai.GenerativeModel(
                current_model_name,
                system_instruction=news_system_instruction,
            )
            st.session_state.news_bot = model.start_chat(history=[])

        # Tin nh·∫Øn ch√†o ƒë·∫ßu ti√™n
        if not st.session_state.news_messages:
            greeting = (
                f"Xin ch√†o üëã\n\nH√¥m nay l√† **{today_str}**.\n"
                "T√¥i l√† **Chuy√™n Gia Tri Th·ª©c & Tin T·ª©c** c·ªßa Rin.Ai.\n\n"
                "B·∫°n h√£y g·ª≠i ch·ªß ƒë·ªÅ tin t·ª©c b·∫°n quan t√¢m (v√≠ d·ª•: *b√°o kinh doanh Vi·ªát Nam h√¥m nay*, "
                "*ch·ª©ng kho√°n Vi·ªát Nam*, *xu h∆∞·ªõng b·∫•t ƒë·ªông s·∫£n*...).\n\n"
                "T√¥i c√≥ th·ªÉ h·ªèi l·∫°i 1‚Äì2 c√¢u cho r√µ, sau ƒë√≥ s·∫Ω t√≥m t·∫Øt & ph√¢n t√≠ch cho b·∫°n.\n"
                "L∆∞u √Ω: t√¥i kh√¥ng th·ªÉ truy c·∫≠p m·ªçi tin n√≥ng 100%, nh∆∞ng s·∫Ω d·ª±a tr√™n ki·∫øn th·ª©c t·ªõi kho·∫£ng nƒÉm 2024 "
                "ƒë·ªÉ ƒë∆∞a b·ª©c tranh t·ªïng quan v√† lu√¥n nh·∫Øc r√µ gi·ªõi h·∫°n."
            )
            st.session_state.news_messages.append(
                {"role": "assistant", "content": greeting}
            )

        # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
        for msg in st.session_state.news_messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        # √î chat ng∆∞·ªùi d√πng
        user_text = st.chat_input("Nh·∫≠p ch·ªß ƒë·ªÅ / c√¢u h·ªèi v·ªÅ tin t·ª©c...")
        if user_text:
            # L∆∞u & hi·ªÉn th·ªã tin nh·∫Øn user
            st.session_state.news_messages.append(
                {"role": "user", "content": user_text}
            )
            with st.chat_message("user"):
                st.markdown(user_text)

            # G·ª≠i v√†o session chat Gemini
            with st.chat_message("assistant"):
                with st.spinner(f"ƒêang d√πng {current_model_name} ƒë·ªÉ ph·∫£n h·ªìi..."):
                    try:
                        response = st.session_state.news_bot.send_message(user_text)
                        answer = (
                            response.text
                            or "Hi·ªán t√¥i ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c, b·∫°n th·ª≠ di·ªÖn ƒë·∫°t l·∫°i ng·∫Øn g·ªçn h∆°n gi√∫p t√¥i nh√©."
                        )
                        st.markdown(answer)
                        play_text_to_speech(answer)
                        st.session_state.news_messages.append(
                            {"role": "assistant", "content": answer}
                        )
                    except Exception as e:
                        err = f"‚ùå L·ªói khi tr√≤ chuy·ªán v·ªÅ tin t·ª©c: {e}"
                        st.error(err)
                        st.session_state.news_messages.append(
                            {"role": "assistant", "content": err}
                        )

    # ==============================
    # 2) CHAT T√ìM T·∫ÆT S√ÅCH / T√ÄI LI·ªÜU
    # ==============================
    else:
        st.subheader("üìö Chat T√≥m t·∫Øt S√°ch / T√†i li·ªáu")

        if "book_chat" not in st.session_state:
            st.session_state.book_chat = [
                {
                    "role": "assistant",
                    "content": (
                        "Xin ch√†o üëã\n\n"
                        "B·∫°n h√£y nh·∫≠p **t√™n s√°ch**, **t√°c gi·∫£** ho·∫∑c **d√°n n·ªôi dung/t√†i li·ªáu** b·∫°n c√≥.\n\n"
                        "T√¥i s·∫Ω gi√∫p b·∫°n t√≥m t·∫Øt 3‚Äì7 √Ω ch√≠nh, r√∫t ra b√†i h·ªçc v√† g·ª£i √Ω c√°ch √°p d·ª•ng th·ª±c t·∫ø. "
                        "B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c ƒë·∫∑t c√¢u h·ªèi follow-up trong c√πng cu·ªôc tr√≤ chuy·ªán n√†y."
                    ),
                }
            ]

        # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat s√°ch
        for msg in st.session_state.book_chat:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        book_msg = st.chat_input("Nh·∫≠p t√™n s√°ch / n·ªôi dung c·∫ßn t√≥m t·∫Øt...")
        if book_msg:
            st.session_state.book_chat.append({"role": "user", "content": book_msg})
            with st.chat_message("user"):
                st.markdown(book_msg)

            with st.chat_message("assistant"):
                with st.spinner(f"ƒêang d√πng {current_model_name} ƒë·ªÉ t√≥m t·∫Øt..."):
                    try:
                        model = genai.GenerativeModel(
                            current_model_name,
                            system_instruction=base_instruction,
                        )

                        # N·∫øu c√≥ file ƒë√≠nh k√®m to√†n phi√™n th√¨ g·ªôp th√™m v√†o
                        if file_content is not None:
                            if isinstance(file_content, Image.Image):
                                req = [
                                    "Ch·∫ø ƒë·ªô: T√ìM T·∫ÆT S√ÅCH/T√ÄI LI·ªÜU.\n"
                                    "Ng∆∞·ªùi d√πng v·ª´a g·ª≠i c√¢u sau (t√™n s√°ch / ghi ch√∫ / c√¢u h·ªèi):\n"
                                    f"{book_msg}\n\n"
                                    "D∆∞·ªõi ƒë√¢y l√† h√¨nh ·∫£nh t√†i li·ªáu h·ªç ƒë√£ ƒë√≠nh k√®m. "
                                    "H√£y ƒë·ªçc v√† t√≥m t·∫Øt c√πng v·ªõi n·ªôi dung ng∆∞·ªùi d√πng ƒë√£ nh·∫≠p:",
                                    file_content,
                                ]
                            else:
                                req = [
                                    "Ch·∫ø ƒë·ªô: T√ìM T·∫ÆT S√ÅCH/T√ÄI LI·ªÜU.\n"
                                    "Ng∆∞·ªùi d√πng v·ª´a g·ª≠i c√¢u sau (t√™n s√°ch / ghi ch√∫ / c√¢u h·ªèi):\n"
                                    f"{book_msg}\n\n"
                                    "ƒê√¢y l√† to√†n b·ªô n·ªôi dung t√†i li·ªáu text ƒëi k√®m:\n"
                                    f"{file_content}\n\n"
                                    "H√£y t√≥m t·∫Øt 3‚Äì7 √Ω ch√≠nh, r√∫t ra b√†i h·ªçc & g·ª£i √Ω ·ª©ng d·ª•ng cho ng∆∞·ªùi Vi·ªát.",
                                ]
                        else:
                            req = [
                                "Ch·∫ø ƒë·ªô: T√ìM T·∫ÆT S√ÅCH/T√ÄI LI·ªÜU.\n"
                                "Ng∆∞·ªùi d√πng ch·ªâ cung c·∫•p n·ªôi dung sau (t√™n s√°ch, m√¥ t·∫£ ho·∫∑c ƒëo·∫°n tr√≠ch). "
                                "D·ª±a tr√™n hi·ªÉu bi·∫øt c·ªßa b·∫°n, h√£y t√≥m t·∫Øt 3‚Äì7 √Ω ch√≠nh v√† g·ª£i √Ω c√°ch √°p d·ª•ng th·ª±c t·∫ø:\n"
                                f"{book_msg}"
                            ]

                        response = model.generate_content(req)
                        answer = (
                            response.text
                            or "Hi·ªán t·∫°i m√¨nh ch∆∞a t√≥m t·∫Øt ƒë∆∞·ª£c n·ªôi dung n√†y, b·∫°n th·ª≠ di·ªÖn ƒë·∫°t l·∫°i gi√∫p m√¨nh nh√©."
                        )
                        st.markdown(answer)
                        play_text_to_speech(answer)
                        st.session_state.book_chat.append(
                            {"role": "assistant", "content": answer}
                        )
                    except Exception as e:
                        err_msg = f"‚ùå L·ªói khi t√≥m t·∫Øt s√°ch/t√†i li·ªáu: {e}"
                        st.error(err_msg)
                        st.session_state.book_chat.append(
                            {"role": "assistant", "content": err_msg}
                        )

# -------------------------------------------------------------
# C√ÅC CHUY√äN GIA THEO NG√ÄNH (CHUNG CHO T·∫§T C·∫¢ MENU C√íN L·∫†I)
# Bao g·ªìm: ‚ú® Tr·ª£ L√Ω ƒêa Lƒ©nh V·ª±c, üé® Media, Office, Ki·∫øn tr√∫c, Lu·∫≠t, Kinh doanh...
# -------------------------------------------------------------
else:
    st.header(menu)

    # L·∫•y c·∫•u h√¨nh chuy√™n gia t·ª´ prompts.py
    expert_instruction = get_expert_prompt(menu)

    # Tu·ª≥ ch·ªânh th√™m cho Gi√°o d·ª•c (ch·ªçn b·ªô s√°ch / vai tr√≤)
    system_append = ""
    if menu == "üéì Gi√°o D·ª•c & ƒê√†o T·∫°o":
        c1, c2 = st.columns(2)
        sach = c1.selectbox(
            "B·ªô s√°ch:",
            ["C√°nh Di·ªÅu", "K·∫øt N·ªëi Tri Th·ª©c", "Ch√¢n Tr·ªùi S√°ng T·∫°o"],
        )
        role = c2.radio(
            "Vai tr√≤:",
            ["H·ªçc sinh", "Gi√°o vi√™n", "Ph·ª• huynh"],
            horizontal=True,
        )
        system_append = f"\n(B·ªô s√°ch: {sach}, ƒê·ªëi t∆∞·ª£ng: {role})."

    # Upload file ri√™ng cho t·ª´ng c√¢u h·ªèi (n·∫±m trong khu chat, d·ªÖ nh√¨n)
    st.markdown("**üìé ƒê√≠nh k√®m t√†i li·ªáu cho c√¢u h·ªèi n√†y (t√πy ch·ªçn):**")
    chat_uploaded_file = st.file_uploader(
        "Ch·ªçn file cho c√¢u h·ªèi (·∫£nh/PDF/Word/Excel...):",
        type=["png", "jpg", "jpeg", "pdf", "txt", "csv", "xlsx", "docx"],
        label_visibility="collapsed",
        key=f"chat_uploader_{menu}",
    )
    chat_file_content = None
    if chat_uploaded_file is not None:
        chat_file_content = process_uploaded_file(chat_uploaded_file)

    # L∆∞u l·ªãch s·ª≠ chat theo t·ª´ng menu chuy√™n gia
    if "history" not in st.session_state:
        st.session_state.history = {}

    if menu not in st.session_state.history:
        st.session_state.history[menu] = [
            {
                "role": "assistant",
                "content": (
                    f"Xin ch√†o! T√¥i l√† **chuy√™n gia {menu}** trong h·ªá sinh th√°i Rin.Ai. "
                    "B·∫°n h√£y m√¥ t·∫£ th·∫≠t r√µ y√™u c·∫ßu, b·ªëi c·∫£nh v√† m·ª•c ti√™u, t√¥i s·∫Ω h·ªó tr·ª£ theo ƒë√∫ng vai tr√≤ & quy tr√¨nh ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh."
                ),
            }
        ]

    # Hi·ªÉn th·ªã l·∫°i l·ªãch s·ª≠ h·ªôi tho·∫°i
    for msg in st.session_state.history[menu]:
        if msg["role"] == "user":
            with st.chat_message("user"):
                st.markdown(msg["content"])
        else:
            # ·∫®n ph·∫ßn PROMPT_2D / 3D khi hi·ªÉn th·ªã, ch·ªâ d√πng n·ªôi b·ªô
            clean_show = re.sub(
                r"###PROMPT_[23]D###.*?###END_PROMPT###",
                "",
                msg["content"],
                flags=re.DOTALL,
            )
            if clean_show.strip():
                with st.chat_message("assistant"):
                    st.markdown(clean_show)

    # √î nh·∫≠p chat
    user_prompt = st.chat_input("G·ª≠i y√™u c·∫ßu cho chuy√™n gia...")

    if user_prompt:
        # X√°c ƒë·ªãnh file s·∫Ω d√πng cho c√¢u h·ªèi n√†y
        used_file_content = (
            chat_file_content if chat_file_content is not None else file_content
        )
        used_file_name = None
        if chat_uploaded_file is not None:
            used_file_name = chat_uploaded_file.name
        elif uploaded_file is not None and file_content is not None:
            used_file_name = uploaded_file.name

        # Hi·ªÉn th·ªã tin nh·∫Øn ng∆∞·ªùi d√πng
        with st.chat_message("user"):
            st.markdown(user_prompt)
            if used_file_name:
                st.caption(f"üìé ƒê√≠nh k√®m: {used_file_name}")

        st.session_state.history[menu].append(
            {"role": "user", "content": user_prompt}
        )

        # G·ªçi model theo ƒë√∫ng chuy√™n gia
        with st.chat_message("assistant"):
            with st.spinner(f"Chuy√™n gia ({current_model_name}) ƒëang ph√¢n t√≠ch..."):
                try:
                    final_prompt = user_prompt + system_append

                    # Chu·∫©n b·ªã payload cho Gemini: n·∫øu c√≥ file th√¨ g·∫Øn th√™m
                    if used_file_content is not None:
                        if isinstance(used_file_content, Image.Image):
                            message_payload = [final_prompt, used_file_content]
                        else:
                            final_prompt += (
                                "\n\n=== FILE DATA (t√≥m t·∫Øt n·ªôi dung ng∆∞·ªùi d√πng g·ª≠i) ===\n"
                                f"{used_file_content}\n"
                                "===================================================="
                            )
                            message_payload = [final_prompt]
                    else:
                        message_payload = [final_prompt]

                    # T·∫°o model & start_chat ƒë·ªÉ c√≥ memory trong t·ª´ng l·∫ßn h·ªèi
                    model = get_model(current_model_name)
                    chat = model.start_chat(
                        system_instruction=expert_instruction,
                        history=[],
                    )
                    response = chat.send_message(message_payload)
                    full_txt = response.text or ""

                    # T√°ch PROMPT_2D / 3D (n·∫øu l√† chuy√™n gia Ki·∫øn tr√∫c)
                    p2d = re.search(
                        r"###PROMPT_2D###(.*?)###END_PROMPT###",
                        full_txt,
                        re.DOTALL,
                    )
                    p3d = re.search(
                        r"###PROMPT_3D###(.*?)###END_PROMPT###",
                        full_txt,
                        re.DOTALL,
                    )
                    txt_show = re.sub(
                        r"###PROMPT_[23]D###.*?###END_PROMPT###",
                        "",
                        full_txt,
                        flags=re.DOTALL,
                    )

                    # Hi·ªÉn th·ªã n·ªôi dung tr·∫£ l·ªùi ch√≠nh
                    st.markdown(txt_show.strip())

                    # N·∫øu c√≥ prompt v·∫Ω 2D/3D ‚Üí demo th√™m ·∫£nh minh ho·∫° (tu·ª≥ ch·ªçn)
                    if p2d or p3d:
                        st.divider()
                        col_a, col_b = st.columns(2)
                        if p2d:
                            with col_a:
                                st.image(
                                    generate_image_url(
                                        "Blueprint floor plan. " + p2d.group(1)
                                    ),
                                    caption="B·∫£n v·∫Ω 2D (demo AI)",
                                )
                        if p3d:
                            with col_b:
                                st.image(
                                    generate_image_url(
                                        "Architecture render 8k. " + p3d.group(1)
                                    ),
                                    caption="Ph·ªëi c·∫£nh 3D (demo AI)",
                                )

                    # L∆∞u v√†o l·ªãch s·ª≠
                    st.session_state.history[menu].append(
                        {"role": "assistant", "content": full_txt}
                    )
                    # Gi·ªõi h·∫°n l·ªãch s·ª≠ ƒë·ªÉ tr√°nh qu√° d√†i
                    if len(st.session_state.history[menu]) > 40:
                        st.session_state.history[menu] = st.session_state.history[
                            menu
                        ][-40:]

                except Exception as e:
                    st.error(f"‚ùå L·ªói khi chuy√™n gia tr·∫£ l·ªùi: {e}")
                    st.warning(
                        "‚ö†Ô∏è N·∫øu g·∫∑p l·ªói, h√£y th·ª≠ ƒë·ªïi sang model 'gemini-1.5-flash' ·ªü thanh b√™n tr√°i."
                    )


